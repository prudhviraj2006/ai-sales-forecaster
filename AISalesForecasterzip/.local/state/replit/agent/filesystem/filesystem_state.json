{"file_contents":{"AISalesForecaster/backend/app/routes/upload.py":{"content":"import os\nimport pandas as pd\nfrom fastapi import APIRouter, UploadFile, File, HTTPException\nfrom typing import List\nimport logging\n\nfrom ..models.schemas import UploadResponse, ValidationResult\nfrom ..models.database import create_job, get_job\nfrom ..services.data_pipeline import DataPipeline\nfrom ..utils.helpers import generate_job_id\n\nrouter = APIRouter()\nlogger = logging.getLogger(__name__)\n\nUPLOAD_DIR = os.environ.get(\"UPLOAD_DIR\", \"backend/uploads\")\nos.makedirs(UPLOAD_DIR, exist_ok=True)\n\n\n@router.post(\"/upload\", response_model=UploadResponse)\nasync def upload_csv(file: UploadFile = File(...)):\n    if not file.filename.endswith('.csv'):\n        raise HTTPException(status_code=400, detail=\"Only CSV files are accepted\")\n    \n    try:\n        contents = await file.read()\n        \n        encodings_to_try = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252', 'iso-8859-1']\n        df = None\n        last_error = None\n        \n        for encoding in encodings_to_try:\n            try:\n                df = pd.read_csv(pd.io.common.BytesIO(contents), encoding=encoding)\n                logger.info(f\"Successfully parsed CSV with encoding: {encoding}\")\n                break\n            except UnicodeDecodeError as e:\n                last_error = e\n                continue\n            except Exception as e:\n                raise HTTPException(status_code=400, detail=f\"Error parsing CSV: {str(e)}\")\n        \n        if df is None:\n            raise HTTPException(status_code=400, detail=f\"Unable to parse CSV file. Please ensure it's a valid CSV with text encoding (UTF-8, Latin-1, or Windows format).\")\n        \n        if len(df) == 0:\n            raise HTTPException(status_code=400, detail=\"CSV file is empty\")\n        \n        job_id = generate_job_id()\n        \n        file_path = os.path.join(UPLOAD_DIR, f\"{job_id}.csv\")\n        with open(file_path, 'wb') as f:\n            f.write(contents)\n        \n        pipeline = DataPipeline(df)\n        validation_result = pipeline.validate()\n        \n        all_columns, numeric_columns, categorical_columns = pipeline.get_column_info()\n        preview = pipeline.get_preview(n=10)\n        \n        date_range = validation_result.date_range or {}\n        \n        create_job(\n            job_id=job_id,\n            file_path=file_path,\n            original_filename=file.filename,\n            row_count=validation_result.row_count,\n            column_count=validation_result.column_count,\n            columns=all_columns,\n            date_range=date_range,\n            validation_result=validation_result.model_dump()\n        )\n        \n        return UploadResponse(\n            job_id=job_id,\n            validation=validation_result,\n            preview=preview,\n            columns=all_columns,\n            numeric_columns=numeric_columns,\n            categorical_columns=categorical_columns\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Upload error: {str(e)}\")\n        raise HTTPException(status_code=500, detail=f\"Error processing file: {str(e)}\")\n\n\n@router.get(\"/job/{job_id}\")\nasync def get_job_info(job_id: str):\n    job = get_job(job_id)\n    if not job:\n        raise HTTPException(status_code=404, detail=\"Job not found\")\n    return job\n","path":null,"size_bytes":3272,"size_tokens":null},"AISalesForecaster/frontend/src/components/ForecastConfig.jsx":{"content":"import { useState } from 'react';\nimport { Settings, Zap, ArrowLeft } from 'lucide-react';\nimport { runForecast, getInsights } from '../services/api';\n\nfunction ForecastConfig({ uploadData, onComplete, setLoading, setLoadingMessage, setError, onBack }) {\n  const [config, setConfig] = useState({\n    aggregation: 'monthly',\n    model: 'prophet',\n    horizon: 6,\n    target_column: 'revenue',\n  });\n\n  const handleSubmit = async (e) => {\n    e.preventDefault();\n    setLoading(true);\n    setLoadingMessage('Running forecast model... This may take a minute.');\n    setError(null);\n\n    try {\n      const forecastResult = await runForecast({\n        job_id: uploadData.job_id,\n        ...config,\n      });\n\n      setLoadingMessage('Generating business insights...');\n      \n      let insightsResult = null;\n      try {\n        insightsResult = await getInsights(uploadData.job_id);\n      } catch (err) {\n        console.warn('Could not generate insights:', err);\n      }\n\n      setLoading(false);\n      onComplete(forecastResult, insightsResult);\n    } catch (err) {\n      setLoading(false);\n      setError(err.response?.data?.detail || 'Failed to run forecast. Please try again.');\n    }\n  };\n\n  return (\n    <div className=\"max-w-2xl mx-auto\">\n      <div className=\"text-center mb-8\">\n        <h2 className=\"text-2xl font-bold text-gray-800 mb-2\">\n          Configure Your Forecast\n        </h2>\n        <p className=\"text-gray-600\">\n          Choose your forecasting parameters to generate predictions\n        </p>\n      </div>\n\n      <form onSubmit={handleSubmit} className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-6 space-y-6\">\n        <div className=\"flex items-center gap-3 pb-4 border-b border-gray-100\">\n          <div className=\"p-2 bg-blue-100 rounded-lg\">\n            <Settings size={24} className=\"text-blue-600\" />\n          </div>\n          <div>\n            <h3 className=\"font-semibold text-gray-800\">Forecast Settings</h3>\n            <p className=\"text-sm text-gray-500\">Job ID: {uploadData.job_id}</p>\n          </div>\n        </div>\n\n        <div className=\"grid md:grid-cols-2 gap-6\">\n          <div>\n            <label className=\"block text-sm font-medium text-gray-700 mb-2\">\n              Target Column\n            </label>\n            <select\n              value={config.target_column}\n              onChange={(e) => setConfig({ ...config, target_column: e.target.value })}\n              className=\"w-full px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-blue-500\"\n            >\n              {uploadData.numeric_columns.map((col) => (\n                <option key={col} value={col}>{col}</option>\n              ))}\n            </select>\n            <p className=\"text-xs text-gray-500 mt-1\">The value you want to forecast</p>\n          </div>\n\n          <div>\n            <label className=\"block text-sm font-medium text-gray-700 mb-2\">\n              Aggregation Level\n            </label>\n            <select\n              value={config.aggregation}\n              onChange={(e) => setConfig({ ...config, aggregation: e.target.value })}\n              className=\"w-full px-4 py-2 border border-gray-300 rounded-lg focus:ring-2 focus:ring-blue-500 focus:border-blue-500\"\n            >\n              <option value=\"daily\">Daily</option>\n              <option value=\"weekly\">Weekly</option>\n              <option value=\"monthly\">Monthly</option>\n            </select>\n            <p className=\"text-xs text-gray-500 mt-1\">How to group your data</p>\n          </div>\n\n          <div>\n            <label className=\"block text-sm font-medium text-gray-700 mb-2\">\n              Forecast Model\n            </label>\n            <div className=\"space-y-2\">\n              <label className=\"flex items-center gap-3 p-3 border border-gray-200 rounded-lg cursor-pointer hover:bg-gray-50\">\n                <input\n                  type=\"radio\"\n                  name=\"model\"\n                  value=\"prophet\"\n                  checked={config.model === 'prophet'}\n                  onChange={(e) => setConfig({ ...config, model: e.target.value })}\n                  className=\"text-blue-600\"\n                />\n                <div>\n                  <span className=\"font-medium text-gray-800\">Prophet</span>\n                  <p className=\"text-xs text-gray-500\">Best for strong seasonality and trend</p>\n                </div>\n              </label>\n              <label className=\"flex items-center gap-3 p-3 border border-gray-200 rounded-lg cursor-pointer hover:bg-gray-50\">\n                <input\n                  type=\"radio\"\n                  name=\"model\"\n                  value=\"lightgbm\"\n                  checked={config.model === 'lightgbm'}\n                  onChange={(e) => setConfig({ ...config, model: e.target.value })}\n                  className=\"text-blue-600\"\n                />\n                <div>\n                  <span className=\"font-medium text-gray-800\">LightGBM</span>\n                  <p className=\"text-xs text-gray-500\">Best for complex patterns with many features</p>\n                </div>\n              </label>\n            </div>\n          </div>\n\n          <div>\n            <label className=\"block text-sm font-medium text-gray-700 mb-2\">\n              Forecast Horizon\n            </label>\n            <div className=\"space-y-2\">\n              {[3, 6, 12].map((months) => (\n                <label \n                  key={months}\n                  className={`flex items-center gap-3 p-3 border rounded-lg cursor-pointer transition-colors ${\n                    config.horizon === months \n                      ? 'border-blue-500 bg-blue-50' \n                      : 'border-gray-200 hover:bg-gray-50'\n                  }`}\n                >\n                  <input\n                    type=\"radio\"\n                    name=\"horizon\"\n                    value={months}\n                    checked={config.horizon === months}\n                    onChange={() => setConfig({ ...config, horizon: months })}\n                    className=\"text-blue-600\"\n                  />\n                  <span className=\"font-medium text-gray-800\">{months} Months</span>\n                </label>\n              ))}\n            </div>\n          </div>\n        </div>\n\n        <div className=\"flex gap-4 pt-4 border-t border-gray-100\">\n          <button\n            type=\"button\"\n            onClick={onBack}\n            className=\"flex items-center gap-2 px-6 py-3 border border-gray-300 rounded-lg font-medium text-gray-700 hover:bg-gray-50 transition-colors\"\n          >\n            <ArrowLeft size={18} />\n            Back\n          </button>\n          <button\n            type=\"submit\"\n            className=\"flex-1 flex items-center justify-center gap-2 px-6 py-3 bg-blue-600 text-white rounded-lg font-semibold hover:bg-blue-700 transition-colors\"\n          >\n            <Zap size={18} />\n            Run Forecast\n          </button>\n        </div>\n      </form>\n    </div>\n  );\n}\n\nexport default ForecastConfig;\n","path":null,"size_bytes":7012,"size_tokens":null},"AISalesForecaster/frontend/vite.config.js":{"content":"import { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\n\nexport default defineConfig({\n  plugins: [react()],\n  server: {\n    host: '0.0.0.0',\n    port: 5000,\n    allowedHosts: true,\n    proxy: {\n      '/api': {\n        target: 'http://localhost:8000',\n        changeOrigin: true,\n      }\n    }\n  }\n})\n","path":null,"size_bytes":322,"size_tokens":null},"AISalesForecaster/frontend/src/services/api.js":{"content":"import axios from 'axios';\n\nconst API_BASE_URL = '/api';\n\nconst api = axios.create({\n  baseURL: API_BASE_URL,\n  headers: {\n    'Content-Type': 'application/json',\n  },\n});\n\nexport const uploadCSV = async (file) => {\n  const formData = new FormData();\n  formData.append('file', file);\n  \n  const response = await api.post('/upload', formData, {\n    headers: {\n      'Content-Type': 'multipart/form-data',\n    },\n  });\n  return response.data;\n};\n\nexport const runForecast = async (params) => {\n  const response = await api.post('/forecast', params);\n  return response.data;\n};\n\nexport const getForecast = async (jobId) => {\n  const response = await api.get(`/forecast/${jobId}`);\n  return response.data;\n};\n\nexport const getInsights = async (jobId) => {\n  const response = await api.get('/insights', {\n    params: { job_id: jobId }\n  });\n  return response.data;\n};\n\nexport const downloadReport = async (jobId, format = 'csv') => {\n  const response = await api.get('/download', {\n    params: { job_id: jobId, format },\n    responseType: 'blob',\n  });\n  \n  const blob = new Blob([response.data]);\n  const url = window.URL.createObjectURL(blob);\n  const link = document.createElement('a');\n  link.href = url;\n  link.download = `forecast_${jobId}.${format}`;\n  document.body.appendChild(link);\n  link.click();\n  document.body.removeChild(link);\n  window.URL.revokeObjectURL(url);\n};\n\nexport default api;\n","path":null,"size_bytes":1398,"size_tokens":null},"AISalesForecaster/frontend/README.md":{"content":"# React + Vite\n\nThis template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.\n\nCurrently, two official plugins are available:\n\n- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react) uses [Babel](https://babeljs.io/) (or [oxc](https://oxc.rs) when used in [rolldown-vite](https://vite.dev/guide/rolldown)) for Fast Refresh\n- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh\n\n## React Compiler\n\nThe React Compiler is not enabled on this template because of its impact on dev & build performances. To add it, see [this documentation](https://react.dev/learn/react-compiler/installation).\n\n## Expanding the ESLint configuration\n\nIf you are developing a production application, we recommend using TypeScript with type-aware lint rules enabled. Check out the [TS template](https://github.com/vitejs/vite/tree/main/packages/create-vite/template-react-ts) for information on how to integrate TypeScript and [`typescript-eslint`](https://typescript-eslint.io) in your project.\n","path":null,"size_bytes":1157,"size_tokens":null},"AISalesForecaster/frontend/src/components/DataPreview.jsx":{"content":"import { CheckCircle, AlertTriangle, Info, Calendar, Hash, Table } from 'lucide-react';\n\nfunction DataPreview({ data }) {\n  const { validation, preview, columns, numeric_columns, categorical_columns } = data;\n\n  return (\n    <div className=\"space-y-6\">\n      <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden\">\n        <div className=\"p-6 border-b border-gray-100\">\n          <h2 className=\"text-xl font-bold text-gray-800\">Data Preview</h2>\n          <p className=\"text-gray-600 mt-1\">Review your uploaded data before proceeding</p>\n        </div>\n\n        <div className=\"grid md:grid-cols-3 gap-4 p-6 bg-gray-50\">\n          <div className=\"flex items-center gap-3 p-4 bg-white rounded-lg shadow-sm\">\n            <div className=\"p-2 bg-blue-100 rounded-lg\">\n              <Table size={20} className=\"text-blue-600\" />\n            </div>\n            <div>\n              <p className=\"text-sm text-gray-500\">Total Rows</p>\n              <p className=\"text-xl font-bold text-gray-800\">{validation.row_count.toLocaleString()}</p>\n            </div>\n          </div>\n          \n          <div className=\"flex items-center gap-3 p-4 bg-white rounded-lg shadow-sm\">\n            <div className=\"p-2 bg-purple-100 rounded-lg\">\n              <Hash size={20} className=\"text-purple-600\" />\n            </div>\n            <div>\n              <p className=\"text-sm text-gray-500\">Columns</p>\n              <p className=\"text-xl font-bold text-gray-800\">{validation.column_count}</p>\n            </div>\n          </div>\n          \n          <div className=\"flex items-center gap-3 p-4 bg-white rounded-lg shadow-sm\">\n            <div className=\"p-2 bg-green-100 rounded-lg\">\n              <Calendar size={20} className=\"text-green-600\" />\n            </div>\n            <div>\n              <p className=\"text-sm text-gray-500\">Date Range</p>\n              <p className=\"text-sm font-semibold text-gray-800\">\n                {validation.date_range ? \n                  `${validation.date_range.start} to ${validation.date_range.end}` : \n                  'N/A'\n                }\n              </p>\n            </div>\n          </div>\n        </div>\n\n        {(validation.errors?.length > 0 || validation.warnings?.length > 0) && (\n          <div className=\"p-6 border-t border-gray-100 space-y-3\">\n            {validation.errors?.map((error, idx) => (\n              <div key={idx} className=\"flex items-start gap-2 text-red-700 bg-red-50 p-3 rounded-lg\">\n                <AlertTriangle size={18} className=\"mt-0.5 flex-shrink-0\" />\n                <span>{error}</span>\n              </div>\n            ))}\n            {validation.warnings?.map((warning, idx) => (\n              <div key={idx} className=\"flex items-start gap-2 text-amber-700 bg-amber-50 p-3 rounded-lg\">\n                <Info size={18} className=\"mt-0.5 flex-shrink-0\" />\n                <span>{warning}</span>\n              </div>\n            ))}\n          </div>\n        )}\n\n        {validation.is_valid && (\n          <div className=\"p-4 border-t border-gray-100 bg-green-50 flex items-center gap-2 text-green-700\">\n            <CheckCircle size={20} />\n            <span className=\"font-medium\">Data validation passed! Ready for forecasting.</span>\n          </div>\n        )}\n      </div>\n\n      <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden\">\n        <div className=\"p-4 border-b border-gray-100\">\n          <h3 className=\"font-semibold text-gray-800\">Sample Data (First 10 rows)</h3>\n        </div>\n        <div className=\"overflow-x-auto\">\n          <table className=\"w-full text-sm\">\n            <thead className=\"bg-gray-50\">\n              <tr>\n                {columns.map((col) => (\n                  <th key={col} className=\"px-4 py-3 text-left font-semibold text-gray-700 whitespace-nowrap\">\n                    {col}\n                    <span className={`ml-2 text-xs px-1.5 py-0.5 rounded ${\n                      numeric_columns.includes(col) \n                        ? 'bg-blue-100 text-blue-700' \n                        : 'bg-gray-200 text-gray-600'\n                    }`}>\n                      {numeric_columns.includes(col) ? 'num' : 'text'}\n                    </span>\n                  </th>\n                ))}\n              </tr>\n            </thead>\n            <tbody className=\"divide-y divide-gray-100\">\n              {preview.map((row, idx) => (\n                <tr key={idx} className=\"hover:bg-gray-50\">\n                  {columns.map((col) => (\n                    <td key={col} className=\"px-4 py-3 text-gray-600 whitespace-nowrap\">\n                      {row[col] !== null && row[col] !== undefined ? String(row[col]) : '-'}\n                    </td>\n                  ))}\n                </tr>\n              ))}\n            </tbody>\n          </table>\n        </div>\n      </div>\n\n      <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-6\">\n        <h3 className=\"font-semibold text-gray-800 mb-4\">Column Summary</h3>\n        <div className=\"grid md:grid-cols-2 gap-6\">\n          <div>\n            <h4 className=\"text-sm font-medium text-gray-500 mb-2\">Numeric Columns ({numeric_columns.length})</h4>\n            <div className=\"flex flex-wrap gap-2\">\n              {numeric_columns.map((col) => (\n                <span key={col} className=\"px-3 py-1 bg-blue-50 text-blue-700 rounded-full text-sm\">\n                  {col}\n                </span>\n              ))}\n            </div>\n          </div>\n          <div>\n            <h4 className=\"text-sm font-medium text-gray-500 mb-2\">Categorical Columns ({categorical_columns.length})</h4>\n            <div className=\"flex flex-wrap gap-2\">\n              {categorical_columns.map((col) => (\n                <span key={col} className=\"px-3 py-1 bg-purple-50 text-purple-700 rounded-full text-sm\">\n                  {col}\n                </span>\n              ))}\n            </div>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nexport default DataPreview;\n","path":null,"size_bytes":6011,"size_tokens":null},"AISalesForecaster/README.md":{"content":"# AI Sales Forecaster & Business Insight Generator\n\nA production-capable prototype application for sales forecasting and business insights generation. Built with FastAPI, React, Prophet, and LightGBM.\n\n## Features\n\n- **Data Upload & Validation**: Upload CSV files with automatic schema validation and data cleaning\n- **Flexible Forecasting**: Choose from Prophet (time-series) or LightGBM (gradient boosting) models\n- **Configurable Parameters**: 3/6/12 month horizons with daily/weekly/monthly aggregation\n- **Interactive Dashboard**: Visualize historical vs forecast data with confidence intervals\n- **Time-Series Decomposition**: View trend, seasonality, and residual components\n- **Feature Importance**: Understand key drivers of your forecasts (LightGBM)\n- **Auto-Generated Insights**: KPI snapshots, data-driven observations, and actionable recommendations\n- **Export Options**: Download forecasts as CSV or comprehensive PDF reports\n\n## Tech Stack\n\n### Backend\n- FastAPI (Python 3.11+)\n- Prophet (Facebook's time-series forecasting)\n- LightGBM (gradient boosting)\n- Pandas, NumPy, scikit-learn\n- SQLite (demo) / PostgreSQL (production)\n- ReportLab (PDF generation)\n\n### Frontend\n- React with Vite\n- Tailwind CSS\n- Recharts (interactive charts)\n- Axios (API client)\n- Lucide Icons\n\n## Quick Start\n\n### Prerequisites\n- Python 3.11+\n- Node.js 18+\n- npm or yarn\n\n### Installation\n\n1. **Clone the repository**\n```bash\ngit clone <repository-url>\ncd ai-sales-forecaster\n```\n\n2. **Install Python dependencies**\n```bash\npip install -r requirements.txt\n```\n\n3. **Install frontend dependencies**\n```bash\ncd frontend\nnpm install\n```\n\n4. **Generate demo data**\n```bash\npython backend/generate_demo_data.py\n```\n\n### Running Locally\n\n1. **Start the backend server**\n```bash\ncd backend\nuvicorn app.main:app --host 0.0.0.0 --port 8000 --reload\n```\n\n2. **Start the frontend server** (in a new terminal)\n```bash\ncd frontend\nnpm run dev\n```\n\n3. **Open the app**: Navigate to `http://localhost:5000`\n\n## API Reference\n\n### Upload CSV\n```http\nPOST /api/upload\nContent-Type: multipart/form-data\n\nfile: <csv-file>\n```\n\n### Run Forecast\n```http\nPOST /api/forecast\nContent-Type: application/json\n\n{\n  \"job_id\": \"string\",\n  \"aggregation\": \"daily|weekly|monthly\",\n  \"model\": \"prophet|lightgbm\",\n  \"horizon\": 3|6|12,\n  \"target_column\": \"revenue\"\n}\n```\n\n### Get Insights\n```http\nGET /api/insights?job_id=<job_id>\n```\n\n### Download Report\n```http\nGET /api/download?job_id=<job_id>&format=csv|pdf\n```\n\n## CSV Format\n\nYour input CSV should contain these columns:\n\n| Column | Type | Required | Description |\n|--------|------|----------|-------------|\n| date | YYYY-MM-DD | Yes | Transaction date |\n| product_id | string | No | Product identifier |\n| product_name | string | No | Product name |\n| region | string | No | Geographic region |\n| units_sold | integer | Yes | Number of units sold |\n| revenue | float | Yes | Revenue amount |\n| price | float | No | Unit price |\n| promotion_flag | 0/1 | No | Promotion indicator |\n\n## Running Tests\n\n```bash\ncd backend\npytest tests/ -v\n```\n\n## Environment Variables\n\n| Variable | Default | Description |\n|----------|---------|-------------|\n| DATABASE_PATH | backend/data/forecaster.db | SQLite database location |\n| UPLOAD_DIR | backend/uploads | File upload directory |\n| SESSION_SECRET | (auto-generated) | Session encryption key |\n\n## Model Selection Guide\n\n### Prophet\n- Best for: Strong seasonal patterns, holiday effects\n- Handles: Missing data, outliers automatically\n- Provides: Uncertainty intervals, decomposition\n\n### LightGBM\n- Best for: Complex patterns, many features\n- Handles: Multivariate forecasting\n- Provides: Feature importance rankings\n\n## Deployment\n\n### Replit\n1. Fork this repository to Replit\n2. The app will auto-start with the configured workflows\n3. Use the web preview to access the application\n\n### Docker\n```bash\ndocker-compose up --build\n```\n\n## License\n\nMIT License - See LICENSE file for details.\n","path":null,"size_bytes":3949,"size_tokens":null},"AISalesForecaster/backend/tests/__init__.py":{"content":"# Tests for AI Sales Forecaster\n","path":null,"size_bytes":32,"size_tokens":null},"AISalesForecaster/backend/app/services/data_pipeline.py":{"content":"import pandas as pd\nimport numpy as np\nfrom typing import Dict, List, Tuple, Optional, Any\nfrom datetime import datetime\nimport logging\n\nfrom ..utils.holidays import get_holiday_flags\nfrom ..models.schemas import ValidationResult, AggregationType\n\nlogger = logging.getLogger(__name__)\n\n\nclass DataPipeline:\n    REQUIRED_COLUMNS = ['date']\n    NUMERIC_COLUMNS = ['units_sold', 'revenue', 'price']\n    OPTIONAL_COLUMNS = ['product_id', 'product_name', 'region', 'promotion_flag']\n    DATE_COLUMN_ALIASES = ['date', 'Date', 'datetime', 'DateTime', 'DATETIME', 'time', 'Time', 'timestamp', 'Timestamp', 'TIMESTAMP']\n    \n    def __init__(self, df: pd.DataFrame):\n        self.raw_df = df.copy()\n        self.processed_df = None\n        self.validation_result = None\n        self._normalize_columns()\n    \n    def _normalize_columns(self) -> None:\n        \"\"\"Auto-detect and normalize date column names\"\"\"\n        for alias in self.DATE_COLUMN_ALIASES:\n            if alias in self.raw_df.columns and alias != 'date':\n                self.raw_df.rename(columns={alias: 'date'}, inplace=True)\n                logger.info(f\"Renamed column '{alias}' to 'date'\")\n                break\n    \n    def validate(self) -> ValidationResult:\n        errors = []\n        warnings = []\n        \n        missing_required = [col for col in self.REQUIRED_COLUMNS if col not in self.raw_df.columns]\n        if missing_required:\n            available_cols = ', '.join(self.raw_df.columns.tolist())\n            errors.append(f\"Missing required 'date' column. Available columns: {available_cols}\")\n        \n        if 'date' in self.raw_df.columns:\n            try:\n                self.raw_df['date'] = pd.to_datetime(self.raw_df['date'], infer_datetime_format=True, errors='coerce')\n                invalid_dates = self.raw_df['date'].isna().sum()\n                if invalid_dates > 0:\n                    warnings.append(f\"{invalid_dates} rows have invalid or missing dates\")\n                if self.raw_df['date'].isna().all():\n                    errors.append(\"All date values are invalid. Please check your date column format.\")\n            except Exception as e:\n                errors.append(f\"Date parsing error: {str(e)}\")\n        \n        numeric_present = [col for col in self.NUMERIC_COLUMNS if col in self.raw_df.columns]\n        if not numeric_present:\n            auto_numeric = self.raw_df.select_dtypes(include=[np.number]).columns.tolist()\n            if auto_numeric:\n                numeric_present = auto_numeric\n                logger.info(f\"Auto-detected numeric columns: {numeric_present}\")\n            else:\n                warnings.append(\"No numeric columns found. You may need to specify a target column for forecasting.\")\n        \n        for col in numeric_present:\n            try:\n                self.raw_df[col] = pd.to_numeric(self.raw_df[col], errors='coerce')\n            except Exception:\n                pass\n        \n        missing_values = {}\n        for col in self.raw_df.columns:\n            null_count = self.raw_df[col].isna().sum()\n            if null_count > 0:\n                missing_values[col] = int(null_count)\n        \n        if missing_values:\n            high_missing = {k: v for k, v in missing_values.items() \n                          if v > len(self.raw_df) * 0.1}\n            if high_missing:\n                warnings.append(f\"High missing values in: {', '.join(high_missing.keys())}\")\n        \n        date_range = None\n        if 'date' in self.raw_df.columns and not self.raw_df['date'].isna().all():\n            try:\n                min_date = self.raw_df['date'].min()\n                max_date = self.raw_df['date'].max()\n                if pd.notna(min_date) and pd.notna(max_date):\n                    date_range = {\n                        'start': pd.Timestamp(min_date).strftime('%Y-%m-%d'),\n                        'end': pd.Timestamp(max_date).strftime('%Y-%m-%d')\n                    }\n            except Exception as e:\n                logger.warning(f\"Could not calculate date range: {str(e)}\")\n        \n        self.validation_result = ValidationResult(\n            is_valid=len(errors) == 0,\n            errors=errors,\n            warnings=warnings,\n            row_count=len(self.raw_df),\n            column_count=len(self.raw_df.columns),\n            date_range=date_range,\n            missing_values=missing_values\n        )\n        \n        return self.validation_result\n    \n    def clean_data(self) -> pd.DataFrame:\n        df = self.raw_df.copy()\n        \n        if 'date' in df.columns:\n            df['date'] = pd.to_datetime(df['date'], errors='coerce')\n            df = df.dropna(subset=['date'])\n        \n        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n        for col in numeric_cols:\n            median_val = df[col].median()\n            df[col] = df[col].fillna(median_val)\n        \n        categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n        if 'date' in categorical_cols:\n            categorical_cols.remove('date')\n        for col in categorical_cols:\n            mode_val = df[col].mode()\n            if len(mode_val) > 0:\n                df[col] = df[col].fillna(mode_val[0])\n        \n        self.processed_df = df\n        return df\n    \n    def handle_outliers(self, columns: List[str] = None) -> pd.DataFrame:\n        if self.processed_df is None:\n            self.clean_data()\n        \n        df = self.processed_df.copy()\n        \n        if columns is None:\n            columns = df.select_dtypes(include=[np.number]).columns.tolist()\n        \n        for col in columns:\n            if col in df.columns:\n                Q1 = df[col].quantile(0.25)\n                Q3 = df[col].quantile(0.75)\n                IQR = Q3 - Q1\n                lower_bound = Q1 - 1.5 * IQR\n                upper_bound = Q3 + 1.5 * IQR\n                \n                df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n        \n        self.processed_df = df\n        return df\n    \n    def aggregate(self, freq: AggregationType, target_column: str = 'revenue',\n                  group_by: Optional[str] = None) -> pd.DataFrame:\n        if self.processed_df is None:\n            self.clean_data()\n        \n        df = self.processed_df.copy()\n        df = df.sort_values('date')\n        \n        freq_map = {\n            AggregationType.DAILY: 'D',\n            AggregationType.WEEKLY: 'W',\n            AggregationType.MONTHLY: 'M'\n        }\n        pd_freq = freq_map.get(freq, 'M')\n        \n        agg_cols = {target_column: 'sum'}\n        \n        if 'units_sold' in df.columns and target_column != 'units_sold':\n            agg_cols['units_sold'] = 'sum'\n        if 'price' in df.columns:\n            agg_cols['price'] = 'mean'\n        if 'promotion_flag' in df.columns:\n            agg_cols['promotion_flag'] = 'max'\n        \n        if group_by and group_by in df.columns:\n            df['period'] = df['date'].dt.to_period(pd_freq)\n            aggregated = df.groupby(['period', group_by]).agg(agg_cols).reset_index()\n            aggregated['date'] = aggregated['period'].dt.to_timestamp()\n            aggregated = aggregated.drop(columns=['period'])\n        else:\n            df.set_index('date', inplace=True)\n            aggregated = df.resample(pd_freq).agg(agg_cols).reset_index()\n        \n        return aggregated\n    \n    def engineer_features(self, df: pd.DataFrame, target_column: str = 'revenue') -> pd.DataFrame:\n        df = df.copy()\n        df = df.sort_values('date')\n        \n        df['year'] = df['date'].dt.year\n        df['month'] = df['date'].dt.month\n        df['day'] = df['date'].dt.day\n        df['day_of_week'] = df['date'].dt.dayofweek\n        df['week_of_year'] = df['date'].dt.isocalendar().week.astype(int)\n        df['quarter'] = df['date'].dt.quarter\n        df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n        df['is_month_start'] = df['date'].dt.is_month_start.astype(int)\n        df['is_month_end'] = df['date'].dt.is_month_end.astype(int)\n        \n        for lag in [1, 7, 14, 30]:\n            df[f'{target_column}_lag_{lag}'] = df[target_column].shift(lag)\n        \n        for window in [7, 14, 30]:\n            df[f'{target_column}_rolling_mean_{window}'] = df[target_column].rolling(window=window, min_periods=1).mean()\n            df[f'{target_column}_rolling_std_{window}'] = df[target_column].rolling(window=window, min_periods=1).std()\n        \n        df[f'{target_column}_diff'] = df[target_column].diff()\n        df[f'{target_column}_pct_change'] = df[target_column].pct_change()\n        \n        if 'price' in df.columns and 'units_sold' in df.columns:\n            df['price_lag_1'] = df['price'].shift(1)\n            df['units_lag_1'] = df['units_sold'].shift(1)\n            \n            price_change = df['price'].pct_change()\n            units_change = df['units_sold'].pct_change()\n            \n            with np.errstate(divide='ignore', invalid='ignore'):\n                df['price_elasticity'] = np.where(\n                    price_change != 0,\n                    units_change / price_change,\n                    0\n                )\n            df['price_elasticity'] = df['price_elasticity'].replace([np.inf, -np.inf], 0).fillna(0)\n        \n        try:\n            holiday_flags = get_holiday_flags(df['date'])\n            df = pd.concat([df.reset_index(drop=True), holiday_flags.reset_index(drop=True)], axis=1)\n        except Exception as e:\n            logger.warning(f\"Could not add holiday flags: {e}\")\n            df['is_holiday'] = 0\n        \n        df = df.fillna(method='bfill').fillna(method='ffill').fillna(0)\n        \n        return df\n    \n    def prepare_for_modeling(self, aggregation: AggregationType, \n                             target_column: str = 'revenue',\n                             group_by: Optional[str] = None) -> pd.DataFrame:\n        self.clean_data()\n        self.handle_outliers()\n        aggregated = self.aggregate(aggregation, target_column, group_by)\n        featured = self.engineer_features(aggregated, target_column)\n        \n        return featured\n    \n    def get_preview(self, n: int = 10) -> List[Dict[str, Any]]:\n        df = self.raw_df.head(n).copy()\n        \n        for col in df.columns:\n            if pd.api.types.is_datetime64_any_dtype(df[col]):\n                df[col] = df[col].dt.strftime('%Y-%m-%d')\n        \n        return df.to_dict(orient='records')\n    \n    def get_column_info(self) -> Tuple[List[str], List[str], List[str]]:\n        all_columns = list(self.raw_df.columns)\n        numeric_columns = list(self.raw_df.select_dtypes(include=[np.number]).columns)\n        categorical_columns = list(self.raw_df.select_dtypes(include=['object', 'category']).columns)\n        \n        return all_columns, numeric_columns, categorical_columns\n    \n    def get_top_by_column(self, df: pd.DataFrame, group_col: str, \n                          value_col: str, n: int = 5) -> List[Dict[str, Any]]:\n        if group_col not in df.columns or value_col not in df.columns:\n            return []\n        \n        grouped = df.groupby(group_col)[value_col].sum().reset_index()\n        grouped = grouped.sort_values(value_col, ascending=False).head(n)\n        \n        return grouped.to_dict(orient='records')\n","path":null,"size_bytes":11273,"size_tokens":null},"AISalesForecaster/backend/app/models/__init__.py":{"content":"from .schemas import *\nfrom .database import *\n","path":null,"size_bytes":47,"size_tokens":null},"AISalesForecaster/frontend/src/index.css":{"content":"@import \"tailwindcss\";\n\n* {\n  box-sizing: border-box;\n}\n\nbody {\n  margin: 0;\n  font-family: 'Inter', system-ui, -apple-system, sans-serif;\n  background-color: #f8fafc;\n}\n\n#root {\n  width: 100%;\n  min-height: 100vh;\n}\n\n.gradient-bg {\n  background: linear-gradient(135deg, #1e40af 0%, #7c3aed 100%);\n}\n\n.card-shadow {\n  box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);\n}\n\n.animate-pulse-slow {\n  animation: pulse 3s cubic-bezier(0.4, 0, 0.6, 1) infinite;\n}\n\n@keyframes pulse {\n  0%, 100% {\n    opacity: 1;\n  }\n  50% {\n    opacity: 0.7;\n  }\n}\n","path":null,"size_bytes":574,"size_tokens":null},"AISalesForecaster/backend/app/models/schemas.py":{"content":"from pydantic import BaseModel, Field\nfrom typing import Optional, List, Dict, Any\nfrom datetime import datetime\nfrom enum import Enum\n\n\nclass AggregationType(str, Enum):\n    DAILY = \"daily\"\n    WEEKLY = \"weekly\"\n    MONTHLY = \"monthly\"\n\n\nclass ModelType(str, Enum):\n    PROPHET = \"prophet\"\n    LIGHTGBM = \"lightgbm\"\n\n\nclass HorizonType(int, Enum):\n    THREE_MONTHS = 3\n    SIX_MONTHS = 6\n    TWELVE_MONTHS = 12\n\n\nclass ValidationResult(BaseModel):\n    is_valid: bool\n    errors: List[str] = []\n    warnings: List[str] = []\n    row_count: int = 0\n    column_count: int = 0\n    date_range: Optional[Dict[str, str]] = None\n    missing_values: Dict[str, int] = {}\n\n\nclass UploadResponse(BaseModel):\n    job_id: str\n    validation: ValidationResult\n    preview: List[Dict[str, Any]]\n    columns: List[str]\n    numeric_columns: List[str]\n    categorical_columns: List[str]\n\n\nclass ForecastRequest(BaseModel):\n    job_id: str\n    aggregation: AggregationType = AggregationType.MONTHLY\n    model: ModelType = ModelType.PROPHET\n    horizon: int = Field(default=6, ge=1, le=24)\n    target_column: str = \"revenue\"\n    group_by: Optional[str] = None\n\n\nclass ForecastMetrics(BaseModel):\n    mae: float\n    rmse: float\n    mape: float\n    train_size: int\n    test_size: int\n\n\nclass ForecastPoint(BaseModel):\n    date: str\n    actual: Optional[float] = None\n    predicted: float\n    lower_bound: Optional[float] = None\n    upper_bound: Optional[float] = None\n\n\nclass DecompositionData(BaseModel):\n    trend: List[Dict[str, Any]]\n    seasonal: List[Dict[str, Any]]\n    residual: List[Dict[str, Any]]\n\n\nclass FeatureImportance(BaseModel):\n    feature: str\n    importance: float\n\n\nclass ForecastResponse(BaseModel):\n    job_id: str\n    model_type: str\n    aggregation: str\n    horizon: int\n    target_column: str\n    metrics: ForecastMetrics\n    forecast: List[ForecastPoint]\n    historical: List[ForecastPoint]\n    decomposition: Optional[DecompositionData] = None\n    feature_importance: Optional[List[FeatureImportance]] = None\n    top_products: Optional[List[Dict[str, Any]]] = None\n    top_regions: Optional[List[Dict[str, Any]]] = None\n\n\nclass InsightBullet(BaseModel):\n    icon: str\n    text: str\n    severity: str = \"info\"\n\n\nclass Recommendation(BaseModel):\n    category: str\n    title: str\n    description: str\n    priority: str = \"medium\"\n\n\nclass KPISnapshot(BaseModel):\n    name: str\n    value: str\n    change: Optional[str] = None\n    trend: str = \"neutral\"\n\n\nclass InsightsResponse(BaseModel):\n    job_id: str\n    title: str\n    summary: str\n    kpis: List[KPISnapshot]\n    bullets: List[InsightBullet]\n    recommendations: List[Recommendation]\n    generated_at: str\n\n\nclass DownloadFormat(str, Enum):\n    CSV = \"csv\"\n    PDF = \"pdf\"\n","path":null,"size_bytes":2730,"size_tokens":null},"AISalesForecaster/backend/app/utils/__init__.py":{"content":"from .holidays import get_holiday_flags\nfrom .helpers import generate_job_id\n","path":null,"size_bytes":77,"size_tokens":null},"AISalesForecaster/frontend/eslint.config.js":{"content":"import js from '@eslint/js'\nimport globals from 'globals'\nimport reactHooks from 'eslint-plugin-react-hooks'\nimport reactRefresh from 'eslint-plugin-react-refresh'\nimport { defineConfig, globalIgnores } from 'eslint/config'\n\nexport default defineConfig([\n  globalIgnores(['dist']),\n  {\n    files: ['**/*.{js,jsx}'],\n    extends: [\n      js.configs.recommended,\n      reactHooks.configs.flat.recommended,\n      reactRefresh.configs.vite,\n    ],\n    languageOptions: {\n      ecmaVersion: 2020,\n      globals: globals.browser,\n      parserOptions: {\n        ecmaVersion: 'latest',\n        ecmaFeatures: { jsx: true },\n        sourceType: 'module',\n      },\n    },\n    rules: {\n      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],\n    },\n  },\n])\n","path":null,"size_bytes":758,"size_tokens":null},"AISalesForecaster/backend/tests/test_insights.py":{"content":"import pytest\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport sys\nimport os\n\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))\n\nfrom app.services.insights_generator import InsightsGenerator\nfrom app.models.schemas import ForecastMetrics, FeatureImportance\n\n\ndef create_sample_historical_df(n_rows=365):\n    dates = pd.date_range(start='2023-01-01', periods=n_rows, freq='D')\n    \n    return pd.DataFrame({\n        'date': dates,\n        'month': dates.month,\n        'revenue': np.random.uniform(1000, 5000, n_rows).round(2),\n        'units_sold': np.random.randint(50, 200, n_rows),\n        'price': np.random.uniform(20, 50, n_rows).round(2),\n        'promotion_flag': np.random.choice([0, 1], n_rows, p=[0.85, 0.15])\n    })\n\n\ndef create_sample_forecast():\n    return [\n        {'date': '2024-01-01', 'predicted': 5000.0, 'lower_bound': 4500.0, 'upper_bound': 5500.0},\n        {'date': '2024-02-01', 'predicted': 5200.0, 'lower_bound': 4700.0, 'upper_bound': 5700.0},\n        {'date': '2024-03-01', 'predicted': 5500.0, 'lower_bound': 5000.0, 'upper_bound': 6000.0},\n    ]\n\n\ndef create_sample_metrics():\n    return ForecastMetrics(\n        mae=150.5,\n        rmse=200.3,\n        mape=8.5,\n        train_size=280,\n        test_size=70\n    )\n\n\nclass TestInsightsGenerator:\n    @pytest.fixture\n    def sample_generator(self):\n        df = create_sample_historical_df()\n        forecast = create_sample_forecast()\n        metrics = create_sample_metrics()\n        \n        return InsightsGenerator(\n            historical_df=df,\n            forecast_data=forecast,\n            metrics=metrics,\n            target_column='revenue'\n        )\n    \n    def test_generate_title(self, sample_generator):\n        title = sample_generator.generate_title()\n        \n        assert isinstance(title, str)\n        assert len(title) > 0\n        assert 'Forecast' in title\n    \n    def test_generate_summary(self, sample_generator):\n        summary = sample_generator.generate_summary()\n        \n        assert isinstance(summary, str)\n        assert len(summary) > 0\n        assert 'revenue' in summary.lower()\n    \n    def test_generate_kpis(self, sample_generator):\n        kpis = sample_generator.generate_kpis()\n        \n        assert isinstance(kpis, list)\n        assert len(kpis) > 0\n        \n        for kpi in kpis:\n            assert hasattr(kpi, 'name')\n            assert hasattr(kpi, 'value')\n            assert hasattr(kpi, 'trend')\n    \n    def test_generate_bullets(self, sample_generator):\n        bullets = sample_generator.generate_bullets()\n        \n        assert isinstance(bullets, list)\n        assert len(bullets) > 0\n        \n        for bullet in bullets:\n            assert hasattr(bullet, 'icon')\n            assert hasattr(bullet, 'text')\n            assert hasattr(bullet, 'severity')\n    \n    def test_generate_recommendations(self, sample_generator):\n        recommendations = sample_generator.generate_recommendations()\n        \n        assert isinstance(recommendations, list)\n        assert len(recommendations) == 3\n        \n        for rec in recommendations:\n            assert hasattr(rec, 'category')\n            assert hasattr(rec, 'title')\n            assert hasattr(rec, 'description')\n            assert hasattr(rec, 'priority')\n    \n    def test_generate_insights_complete(self, sample_generator):\n        insights = sample_generator.generate_insights()\n        \n        assert 'title' in insights\n        assert 'summary' in insights\n        assert 'kpis' in insights\n        assert 'bullets' in insights\n        assert 'recommendations' in insights\n        assert 'generated_at' in insights\n    \n    def test_with_feature_importance(self):\n        df = create_sample_historical_df()\n        forecast = create_sample_forecast()\n        metrics = create_sample_metrics()\n        \n        feature_importance = [\n            FeatureImportance(feature='month', importance=25.5),\n            FeatureImportance(feature='revenue_lag_1', importance=20.3),\n            FeatureImportance(feature='day_of_week', importance=15.2),\n        ]\n        \n        generator = InsightsGenerator(\n            historical_df=df,\n            forecast_data=forecast,\n            metrics=metrics,\n            target_column='revenue',\n            feature_importance=feature_importance\n        )\n        \n        bullets = generator.generate_bullets()\n        \n        driver_bullet = [b for b in bullets if 'driver' in b.text.lower()]\n        assert len(driver_bullet) > 0\n\n\nclass TestInsightsQuality:\n    def test_high_accuracy_title(self):\n        df = create_sample_historical_df()\n        forecast = create_sample_forecast()\n        \n        metrics = ForecastMetrics(mae=50, rmse=70, mape=5.0, train_size=280, test_size=70)\n        \n        generator = InsightsGenerator(df, forecast, metrics, 'revenue')\n        title = generator.generate_title()\n        \n        assert 'High-Confidence' in title\n    \n    def test_low_accuracy_title(self):\n        df = create_sample_historical_df()\n        forecast = create_sample_forecast()\n        \n        metrics = ForecastMetrics(mae=500, rmse=700, mape=35.0, train_size=280, test_size=70)\n        \n        generator = InsightsGenerator(df, forecast, metrics, 'revenue')\n        title = generator.generate_title()\n        \n        assert 'Indicative' in title\n    \n    def test_seasonality_detection(self):\n        dates = pd.date_range(start='2023-01-01', periods=365, freq='D')\n        \n        seasonal_pattern = np.sin(np.linspace(0, 4*np.pi, 365)) * 500 + 2000\n        \n        df = pd.DataFrame({\n            'date': dates,\n            'month': dates.month,\n            'revenue': seasonal_pattern,\n            'units_sold': (seasonal_pattern / 20).astype(int),\n            'price': 20.0,\n            'promotion_flag': 0\n        })\n        \n        generator = InsightsGenerator(\n            df, \n            create_sample_forecast(), \n            create_sample_metrics(),\n            'revenue'\n        )\n        \n        bullets = generator.generate_bullets()\n        seasonal_bullets = [b for b in bullets if 'peak' in b.text.lower() or 'seasonal' in b.text.lower()]\n        assert len(seasonal_bullets) > 0\n\n\nif __name__ == '__main__':\n    pytest.main([__file__, '-v'])\n","path":null,"size_bytes":6279,"size_tokens":null},"AISalesForecaster/backend/app/__init__.py":{"content":"","path":null,"size_bytes":0,"size_tokens":null},"AISalesForecaster/backend/app/services/insights_generator.py":{"content":"import pandas as pd\nimport numpy as np\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\nimport logging\n\nfrom ..models.schemas import (\n    InsightBullet, Recommendation, KPISnapshot,\n    ForecastMetrics, FeatureImportance\n)\nfrom ..utils.helpers import format_number, format_percentage, calculate_change_percentage\n\nlogger = logging.getLogger(__name__)\n\n\nclass InsightsGenerator:\n    def __init__(self, historical_df: pd.DataFrame, forecast_data: List[Dict],\n                 metrics: ForecastMetrics, target_column: str = 'revenue',\n                 feature_importance: Optional[List[FeatureImportance]] = None):\n        self.historical_df = historical_df.copy()\n        self.forecast_data = forecast_data\n        self.metrics = metrics\n        self.target_column = target_column\n        self.feature_importance = feature_importance or []\n    \n    def generate_title(self) -> str:\n        accuracy = 100 - self.metrics.mape\n        if accuracy >= 90:\n            quality = \"High-Confidence\"\n        elif accuracy >= 80:\n            quality = \"Reliable\"\n        else:\n            quality = \"Indicative\"\n        \n        return f\"{quality} Sales Forecast Analysis\"\n    \n    def generate_summary(self) -> str:\n        total_historical = self.historical_df[self.target_column].sum()\n        avg_historical = self.historical_df[self.target_column].mean()\n        \n        forecast_values = [f['predicted'] for f in self.forecast_data if 'predicted' in f]\n        total_forecast = sum(forecast_values) if forecast_values else 0\n        avg_forecast = np.mean(forecast_values) if forecast_values else 0\n        \n        growth = calculate_change_percentage(avg_forecast, avg_historical)\n        \n        trend = \"growth\" if growth > 0 else \"decline\" if growth < 0 else \"stable performance\"\n        \n        summary = (\n            f\"Based on analysis of {len(self.historical_df)} historical data points, \"\n            f\"our model forecasts {format_number(total_forecast)} in projected {self.target_column} \"\n            f\"over the next {len(self.forecast_data)} periods. \"\n            f\"This represents a {abs(growth):.1f}% {trend} compared to historical averages. \"\n            f\"Model accuracy: {100 - self.metrics.mape:.1f}% (MAPE: {self.metrics.mape:.1f}%).\"\n        )\n        \n        return summary\n    \n    def generate_kpis(self) -> List[KPISnapshot]:\n        kpis = []\n        \n        current_year = self.historical_df['date'].dt.year.max()\n        prev_year = current_year - 1\n        \n        current_year_data = self.historical_df[self.historical_df['date'].dt.year == current_year]\n        prev_year_data = self.historical_df[self.historical_df['date'].dt.year == prev_year]\n        \n        current_total = current_year_data[self.target_column].sum()\n        prev_total = prev_year_data[self.target_column].sum() if len(prev_year_data) > 0 else 0\n        \n        if prev_total > 0:\n            yoy_growth = calculate_change_percentage(current_total, prev_total)\n            kpis.append(KPISnapshot(\n                name=\"Year-over-Year Growth\",\n                value=format_percentage(yoy_growth),\n                trend=\"up\" if yoy_growth > 0 else \"down\" if yoy_growth < 0 else \"neutral\"\n            ))\n        \n        forecast_values = [f['predicted'] for f in self.forecast_data]\n        if forecast_values:\n            forecast_growth = calculate_change_percentage(\n                np.mean(forecast_values),\n                self.historical_df[self.target_column].mean()\n            )\n            kpis.append(KPISnapshot(\n                name=\"Forecast vs Historical\",\n                value=format_percentage(forecast_growth),\n                trend=\"up\" if forecast_growth > 0 else \"down\" if forecast_growth < 0 else \"neutral\"\n            ))\n        \n        kpis.append(KPISnapshot(\n            name=\"Model Accuracy\",\n            value=f\"{100 - self.metrics.mape:.1f}%\",\n            trend=\"up\" if self.metrics.mape < 15 else \"neutral\" if self.metrics.mape < 25 else \"down\"\n        ))\n        \n        kpis.append(KPISnapshot(\n            name=\"MAE\",\n            value=format_number(self.metrics.mae),\n            trend=\"neutral\"\n        ))\n        \n        if 'month' in self.historical_df.columns:\n            monthly_avg = self.historical_df.groupby('month')[self.target_column].mean()\n            peak_month = monthly_avg.idxmax()\n            seasonality_strength = (monthly_avg.max() - monthly_avg.min()) / monthly_avg.mean() * 100\n            \n            kpis.append(KPISnapshot(\n                name=\"Seasonality Strength\",\n                value=f\"{seasonality_strength:.0f}%\",\n                change=f\"Peak: Month {peak_month}\",\n                trend=\"up\" if seasonality_strength > 30 else \"neutral\"\n            ))\n        \n        return kpis\n    \n    def generate_bullets(self) -> List[InsightBullet]:\n        bullets = []\n        \n        total = self.historical_df[self.target_column].sum()\n        avg = self.historical_df[self.target_column].mean()\n        \n        bullets.append(InsightBullet(\n            icon=\"chart-line\",\n            text=f\"Total historical {self.target_column}: {format_number(total)} with average of {format_number(avg)} per period.\",\n            severity=\"info\"\n        ))\n        \n        if 'month' in self.historical_df.columns:\n            monthly_data = self.historical_df.groupby('month')[self.target_column].mean()\n            peak_month = monthly_data.idxmax()\n            low_month = monthly_data.idxmin()\n            \n            month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n                          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n            \n            peak_name = month_names[peak_month - 1] if 1 <= peak_month <= 12 else str(peak_month)\n            low_name = month_names[low_month - 1] if 1 <= low_month <= 12 else str(low_month)\n            \n            variance = (monthly_data.max() - monthly_data.min()) / monthly_data.mean() * 100\n            \n            if variance > 30:\n                bullets.append(InsightBullet(\n                    icon=\"calendar-check\",\n                    text=f\"Strong seasonal pattern detected: Peak sales in {peak_name}, lowest in {low_name} ({variance:.0f}% variance).\",\n                    severity=\"warning\"\n                ))\n            else:\n                bullets.append(InsightBullet(\n                    icon=\"calendar\",\n                    text=f\"Relatively stable sales across months with slight peaks in {peak_name}.\",\n                    severity=\"info\"\n                ))\n        \n        forecast_values = [f['predicted'] for f in self.forecast_data]\n        if forecast_values:\n            forecast_trend = np.polyfit(range(len(forecast_values)), forecast_values, 1)[0]\n            \n            if forecast_trend > 0:\n                bullets.append(InsightBullet(\n                    icon=\"trending-up\",\n                    text=f\"Forecast shows upward trend with projected growth over the forecast period.\",\n                    severity=\"success\"\n                ))\n            elif forecast_trend < 0:\n                bullets.append(InsightBullet(\n                    icon=\"trending-down\",\n                    text=f\"Forecast indicates declining trend. Consider strategic interventions.\",\n                    severity=\"warning\"\n                ))\n            else:\n                bullets.append(InsightBullet(\n                    icon=\"minus\",\n                    text=\"Forecast shows stable performance with minimal variation expected.\",\n                    severity=\"info\"\n                ))\n        \n        if self.feature_importance:\n            top_features = self.feature_importance[:3]\n            feature_names = [f.feature.replace('_', ' ').title() for f in top_features]\n            \n            bullets.append(InsightBullet(\n                icon=\"zap\",\n                text=f\"Top sales drivers: {', '.join(feature_names)}.\",\n                severity=\"info\"\n            ))\n        \n        if self.metrics.mape < 10:\n            bullets.append(InsightBullet(\n                icon=\"check-circle\",\n                text=\"Excellent model accuracy (<10% error). High confidence in forecasts.\",\n                severity=\"success\"\n            ))\n        elif self.metrics.mape < 20:\n            bullets.append(InsightBullet(\n                icon=\"check\",\n                text=\"Good model accuracy. Forecasts are reliable for planning purposes.\",\n                severity=\"info\"\n            ))\n        else:\n            bullets.append(InsightBullet(\n                icon=\"alert-triangle\",\n                text=\"Model accuracy is moderate. Consider using forecasts as directional guidance.\",\n                severity=\"warning\"\n            ))\n        \n        return bullets\n    \n    def generate_recommendations(self) -> List[Recommendation]:\n        recommendations = []\n        \n        if 'month' in self.historical_df.columns:\n            monthly_data = self.historical_df.groupby('month')[self.target_column].mean()\n            peak_months = monthly_data.nlargest(3).index.tolist()\n            low_months = monthly_data.nsmallest(3).index.tolist()\n            \n            month_names = ['January', 'February', 'March', 'April', 'May', 'June',\n                          'July', 'August', 'September', 'October', 'November', 'December']\n            \n            peak_names = [month_names[m-1] for m in peak_months if 1 <= m <= 12]\n            low_names = [month_names[m-1] for m in low_months if 1 <= m <= 12]\n            \n            recommendations.append(Recommendation(\n                category=\"Inventory\",\n                title=\"Optimize Inventory Levels\",\n                description=f\"Increase inventory 4-6 weeks before peak months ({', '.join(peak_names)}). \"\n                           f\"Reduce stock commitments during {', '.join(low_names)} to minimize carrying costs.\",\n                priority=\"high\"\n            ))\n        \n        if 'promotion_flag' in self.historical_df.columns:\n            promo_data = self.historical_df.groupby('promotion_flag')[self.target_column].mean()\n            if len(promo_data) > 1 and 1 in promo_data.index and 0 in promo_data.index:\n                promo_lift = (promo_data[1] - promo_data[0]) / promo_data[0] * 100\n                \n                if promo_lift > 20:\n                    recommendations.append(Recommendation(\n                        category=\"Promotion\",\n                        title=\"Scale Successful Promotions\",\n                        description=f\"Promotions drive {promo_lift:.0f}% sales lift. \"\n                                   \"Consider increasing promotion frequency during slow periods.\",\n                        priority=\"high\"\n                    ))\n                else:\n                    recommendations.append(Recommendation(\n                        category=\"Promotion\",\n                        title=\"Reassess Promotion Strategy\",\n                        description=f\"Current promotions show only {promo_lift:.0f}% lift. \"\n                                   \"Test different promotion types or discount depths.\",\n                        priority=\"medium\"\n                    ))\n        else:\n            recommendations.append(Recommendation(\n                category=\"Promotion\",\n                title=\"Implement Promotion Tracking\",\n                description=\"Start tracking promotion periods to measure ROI and optimize timing. \"\n                           \"Consider strategic promotions during identified slow periods.\",\n                priority=\"medium\"\n            ))\n        \n        if 'price' in self.historical_df.columns:\n            price_revenue_corr = self.historical_df['price'].corr(self.historical_df[self.target_column])\n            \n            if price_revenue_corr > 0.3:\n                recommendations.append(Recommendation(\n                    category=\"Pricing\",\n                    title=\"Premium Pricing Opportunity\",\n                    description=\"Higher prices correlate with higher revenue. Consider gradual price increases \"\n                               \"or premium product tier development.\",\n                    priority=\"medium\"\n                ))\n            elif price_revenue_corr < -0.3:\n                recommendations.append(Recommendation(\n                    category=\"Pricing\",\n                    title=\"Optimize Price Points\",\n                    description=\"Price sensitivity detected. Test lower price points or bundle offers \"\n                               \"to maximize volume and total revenue.\",\n                    priority=\"high\"\n                ))\n            else:\n                recommendations.append(Recommendation(\n                    category=\"Pricing\",\n                    title=\"Conduct Pricing Analysis\",\n                    description=\"Price-revenue relationship is not clear. Conduct A/B price testing \"\n                               \"to identify optimal price points for different segments.\",\n                    priority=\"low\"\n                ))\n        \n        if len(recommendations) < 3:\n            recommendations.append(Recommendation(\n                category=\"Data Quality\",\n                title=\"Enhance Data Collection\",\n                description=\"Consider tracking additional variables like customer segments, \"\n                           \"marketing channels, and competitor actions for improved forecasting.\",\n                priority=\"low\"\n            ))\n        \n        return recommendations[:3]\n    \n    def generate_insights(self) -> Dict[str, Any]:\n        return {\n            'title': self.generate_title(),\n            'summary': self.generate_summary(),\n            'kpis': [kpi.model_dump() for kpi in self.generate_kpis()],\n            'bullets': [bullet.model_dump() for bullet in self.generate_bullets()],\n            'recommendations': [rec.model_dump() for rec in self.generate_recommendations()],\n            'generated_at': datetime.utcnow().isoformat()\n        }\n","path":null,"size_bytes":13948,"size_tokens":null},"AISalesForecaster/backend/app/main.py":{"content":"import os\nimport logging\nfrom fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom contextlib import asynccontextmanager\n\nfrom .models.database import init_database\nfrom .routes import upload_router, forecast_router, insights_router, download_router\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(__name__)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    logger.info(\"Starting AI Sales Forecaster API...\")\n    init_database()\n    logger.info(\"Database initialized\")\n    yield\n    logger.info(\"Shutting down AI Sales Forecaster API...\")\n\n\napp = FastAPI(\n    title=\"AI Sales Forecaster & Business Insight Generator\",\n    description=\"Production-capable API for sales forecasting using Prophet and LightGBM models\",\n    version=\"1.0.0\",\n    lifespan=lifespan\n)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\napp.include_router(upload_router, prefix=\"/api\", tags=[\"Upload\"])\napp.include_router(forecast_router, prefix=\"/api\", tags=[\"Forecast\"])\napp.include_router(insights_router, prefix=\"/api\", tags=[\"Insights\"])\napp.include_router(download_router, prefix=\"/api\", tags=[\"Download\"])\n\n\n@app.get(\"/\")\nasync def root():\n    return {\n        \"name\": \"AI Sales Forecaster & Business Insight Generator\",\n        \"version\": \"1.0.0\",\n        \"status\": \"running\",\n        \"endpoints\": {\n            \"upload\": \"/api/upload\",\n            \"forecast\": \"/api/forecast\",\n            \"insights\": \"/api/insights\",\n            \"download\": \"/api/download\"\n        }\n    }\n\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\"}\n","path":null,"size_bytes":1765,"size_tokens":null},"AISalesForecaster/backend/app/services/__init__.py":{"content":"from .data_pipeline import DataPipeline\nfrom .forecaster import Forecaster\nfrom .insights_generator import InsightsGenerator\n","path":null,"size_bytes":125,"size_tokens":null},"AISalesForecaster/frontend/src/components/FileUpload.jsx":{"content":"import { useCallback, useState } from 'react';\nimport { useDropzone } from 'react-dropzone';\nimport { Upload, FileSpreadsheet, AlertCircle, CheckCircle } from 'lucide-react';\nimport { uploadCSV } from '../services/api';\n\nfunction FileUpload({ onUploadSuccess, setLoading, setLoadingMessage, setError }) {\n  const [uploadStatus, setUploadStatus] = useState(null);\n\n  const onDrop = useCallback(async (acceptedFiles) => {\n    const file = acceptedFiles[0];\n    if (!file) return;\n\n    if (!file.name.endsWith('.csv')) {\n      setError('Please upload a CSV file');\n      return;\n    }\n\n    setLoading(true);\n    setLoadingMessage('Uploading and validating your data...');\n    setUploadStatus('uploading');\n    setError(null);\n\n    try {\n      const data = await uploadCSV(file);\n      setUploadStatus('success');\n      \n      setTimeout(() => {\n        setLoading(false);\n        onUploadSuccess(data);\n      }, 500);\n    } catch (err) {\n      setLoading(false);\n      setUploadStatus('error');\n      setError(err.response?.data?.detail || 'Failed to upload file. Please try again.');\n    }\n  }, [onUploadSuccess, setLoading, setLoadingMessage, setError]);\n\n  const { getRootProps, getInputProps, isDragActive } = useDropzone({\n    onDrop,\n    accept: {\n      'text/csv': ['.csv'],\n    },\n    maxFiles: 1,\n  });\n\n  return (\n    <div className=\"max-w-2xl mx-auto\">\n      <div className=\"text-center mb-8\">\n        <h2 className=\"text-2xl font-bold text-gray-800 mb-2\">\n          Upload Your Sales Data\n        </h2>\n        <p className=\"text-gray-600\">\n          Upload a CSV file with your historical sales data to get started with forecasting\n        </p>\n      </div>\n\n      <div\n        {...getRootProps()}\n        className={`\n          border-2 border-dashed rounded-xl p-12 text-center cursor-pointer transition-all\n          ${isDragActive \n            ? 'border-blue-500 bg-blue-50' \n            : 'border-gray-300 hover:border-blue-400 hover:bg-gray-50'\n          }\n          ${uploadStatus === 'error' ? 'border-red-300 bg-red-50' : ''}\n          ${uploadStatus === 'success' ? 'border-green-300 bg-green-50' : ''}\n        `}\n      >\n        <input {...getInputProps()} />\n        \n        <div className=\"flex flex-col items-center gap-4\">\n          {uploadStatus === 'success' ? (\n            <CheckCircle size={48} className=\"text-green-500\" />\n          ) : uploadStatus === 'error' ? (\n            <AlertCircle size={48} className=\"text-red-500\" />\n          ) : (\n            <div className={`p-4 rounded-full ${isDragActive ? 'bg-blue-100' : 'bg-gray-100'}`}>\n              <Upload size={32} className={isDragActive ? 'text-blue-600' : 'text-gray-400'} />\n            </div>\n          )}\n          \n          <div>\n            <p className=\"text-lg font-medium text-gray-700\">\n              {isDragActive ? 'Drop your file here' : 'Drag and drop your CSV file'}\n            </p>\n            <p className=\"text-gray-500 mt-1\">or click to browse</p>\n          </div>\n        </div>\n      </div>\n\n      <div className=\"mt-8 bg-white rounded-xl p-6 shadow-sm border border-gray-100\">\n        <div className=\"flex items-start gap-3\">\n          <FileSpreadsheet className=\"text-blue-600 mt-1\" size={24} />\n          <div>\n            <h3 className=\"font-semibold text-gray-800 mb-2\">Expected CSV Format</h3>\n            <p className=\"text-sm text-gray-600 mb-3\">\n              Your CSV should contain the following columns:\n            </p>\n            <div className=\"grid grid-cols-2 md:grid-cols-4 gap-2 text-sm\">\n              <span className=\"px-2 py-1 bg-blue-50 text-blue-700 rounded\">date</span>\n              <span className=\"px-2 py-1 bg-blue-50 text-blue-700 rounded\">product_id</span>\n              <span className=\"px-2 py-1 bg-blue-50 text-blue-700 rounded\">region</span>\n              <span className=\"px-2 py-1 bg-blue-50 text-blue-700 rounded\">units_sold</span>\n              <span className=\"px-2 py-1 bg-blue-50 text-blue-700 rounded\">revenue</span>\n              <span className=\"px-2 py-1 bg-blue-50 text-blue-700 rounded\">price</span>\n              <span className=\"px-2 py-1 bg-gray-100 text-gray-600 rounded\">promotion_flag*</span>\n              <span className=\"px-2 py-1 bg-gray-100 text-gray-600 rounded\">product_name*</span>\n            </div>\n            <p className=\"text-xs text-gray-500 mt-2\">* Optional columns</p>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nexport default FileUpload;\n","path":null,"size_bytes":4449,"size_tokens":null},"AISalesForecaster/backend/app/utils/helpers.py":{"content":"import uuid\nimport hashlib\nfrom datetime import datetime\nfrom typing import List, Any\n\n\ndef generate_job_id() -> str:\n    timestamp = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n    unique_part = uuid.uuid4().hex[:8]\n    return f\"job_{timestamp}_{unique_part}\"\n\n\ndef calculate_change_percentage(current: float, previous: float) -> float:\n    if previous == 0:\n        return 0.0 if current == 0 else 100.0\n    return ((current - previous) / abs(previous)) * 100\n\n\ndef format_number(value: float, decimals: int = 2) -> str:\n    if abs(value) >= 1_000_000_000:\n        return f\"{value / 1_000_000_000:.{decimals}f}B\"\n    elif abs(value) >= 1_000_000:\n        return f\"{value / 1_000_000:.{decimals}f}M\"\n    elif abs(value) >= 1_000:\n        return f\"{value / 1_000:.{decimals}f}K\"\n    else:\n        return f\"{value:.{decimals}f}\"\n\n\ndef format_percentage(value: float, decimals: int = 1) -> str:\n    return f\"{value:+.{decimals}f}%\"\n\n\ndef safe_divide(numerator: float, denominator: float, default: float = 0.0) -> float:\n    if denominator == 0:\n        return default\n    return numerator / denominator\n\n\ndef get_season(month: int) -> str:\n    if month in [12, 1, 2]:\n        return \"Winter\"\n    elif month in [3, 4, 5]:\n        return \"Spring\"\n    elif month in [6, 7, 8]:\n        return \"Summer\"\n    else:\n        return \"Fall\"\n\n\ndef get_quarter(month: int) -> int:\n    return (month - 1) // 3 + 1\n\n\ndef chunk_list(lst: List[Any], chunk_size: int) -> List[List[Any]]:\n    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n","path":null,"size_bytes":1542,"size_tokens":null},"AISalesForecaster/frontend/postcss.config.js":{"content":"export default {\n  plugins: {\n    '@tailwindcss/postcss': {},\n  },\n}\n","path":null,"size_bytes":69,"size_tokens":null},"AISalesForecaster/main.py":{"content":"def main():\n    print(\"Hello from repl-nix-workspace!\")\n\n\nif __name__ == \"__main__\":\n    main()\n","path":null,"size_bytes":96,"size_tokens":null},"AISalesForecaster/replit.md":{"content":"# AI Sales Forecaster & Business Insight Generator\n\n## Overview\nA production-capable prototype app that helps non-technical business users upload historical sales data, get reliable forecasts using Prophet or LightGBM models, and receive automated, actionable business insights.\n\n## Project Structure\n```\n backend/\n    app/\n       main.py          # FastAPI application entry point\n       models/          # Database models and Pydantic schemas\n       routes/          # API endpoints\n       services/        # Business logic (forecaster, data pipeline, insights)\n       utils/           # Helper functions\n    tests/               # Pytest unit tests\n    data/                # Demo data and SQLite database\n    generate_demo_data.py # Demo data generation script\n frontend/\n    src/\n       components/      # React components\n       services/        # API client\n       App.jsx          # Main application\n    package.json         # Frontend dependencies\n README.md                # Documentation\n```\n\n## Tech Stack\n- **Backend**: FastAPI, Python 3.11, Prophet, LightGBM, SQLite\n- **Frontend**: React, Vite, Tailwind CSS, Recharts\n- **ML/Stats**: Prophet (time-series), LightGBM (gradient boosting), scikit-learn\n\n## Running the Application\nThe app runs on two servers:\n1. **Backend API**: Port 8000 (FastAPI with Uvicorn)\n2. **Frontend**: Port 5000 (Vite dev server)\n\n## Key Features\n- CSV upload with data validation and preview\n- Configurable forecasting (3/6/12 month horizons, daily/weekly/monthly aggregation)\n- Prophet and LightGBM model options\n- Interactive charts with historical vs forecast comparison\n- Time-series decomposition (trend, seasonality)\n- Auto-generated business insights with KPIs and recommendations\n- CSV and PDF export functionality\n\n## API Endpoints\n- `POST /api/upload` - Upload CSV file\n- `POST /api/forecast` - Run forecast with parameters\n- `GET /api/insights?job_id=` - Get generated insights\n- `GET /api/download?job_id=&format=csv|pdf` - Download report\n\n## Environment Variables\n- `DATABASE_PATH` - SQLite database path (default: backend/data/forecaster.db)\n- `UPLOAD_DIR` - Upload directory (default: backend/uploads)\n\n## Recent Changes\n- Initial project setup with full-stack implementation\n- Created backend with FastAPI, Prophet, and LightGBM models\n- Built React frontend with Recharts visualization\n- Implemented data pipeline with feature engineering\n- Added insights generator with business recommendations\n","path":null,"size_bytes":2674,"size_tokens":null},"AISalesForecaster/backend/app/routes/forecast.py":{"content":"import os\nimport pandas as pd\nfrom fastapi import APIRouter, HTTPException\nfrom typing import Optional\nimport logging\n\nfrom ..models.schemas import (\n    ForecastRequest, ForecastResponse, ModelType, AggregationType\n)\nfrom ..models.database import (\n    get_job, update_job_status, save_forecast, get_latest_forecast\n)\nfrom ..services.data_pipeline import DataPipeline\nfrom ..services.forecaster import Forecaster\n\nrouter = APIRouter()\nlogger = logging.getLogger(__name__)\n\n\n@router.post(\"/forecast\", response_model=ForecastResponse)\nasync def run_forecast(request: ForecastRequest):\n    job = get_job(request.job_id)\n    if not job:\n        raise HTTPException(status_code=404, detail=\"Job not found. Please upload a file first.\")\n    \n    if not os.path.exists(job['file_path']):\n        raise HTTPException(status_code=404, detail=\"Data file not found\")\n    \n    try:\n        update_job_status(request.job_id, 'processing')\n        \n        encodings_to_try = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252', 'iso-8859-1']\n        df = None\n        for encoding in encodings_to_try:\n            try:\n                df = pd.read_csv(job['file_path'], encoding=encoding)\n                logger.info(f\"Successfully parsed forecast CSV with encoding: {encoding}\")\n                break\n            except UnicodeDecodeError:\n                continue\n        \n        if df is None:\n            raise HTTPException(status_code=400, detail=\"Unable to parse CSV file with any known encoding\")\n        \n        pipeline = DataPipeline(df)\n        processed_df = pipeline.prepare_for_modeling(\n            aggregation=request.aggregation,\n            target_column=request.target_column,\n            group_by=request.group_by\n        )\n        \n        if request.target_column not in processed_df.columns:\n            raise HTTPException(\n                status_code=400, \n                detail=f\"Target column '{request.target_column}' not found in data\"\n            )\n        \n        forecaster = Forecaster(processed_df, request.target_column)\n        results = forecaster.forecast(\n            model_type=request.model,\n            horizon=request.horizon,\n            aggregation=request.aggregation\n        )\n        \n        top_products = None\n        top_regions = None\n        \n        if 'product_name' in df.columns or 'product_id' in df.columns:\n            product_col = 'product_name' if 'product_name' in df.columns else 'product_id'\n            top_products = pipeline.get_top_by_column(df, product_col, request.target_column, n=5)\n        \n        if 'region' in df.columns:\n            top_regions = pipeline.get_top_by_column(df, 'region', request.target_column, n=5)\n        \n        save_forecast(\n            job_id=request.job_id,\n            model_type=request.model.value,\n            aggregation=request.aggregation.value,\n            horizon=request.horizon,\n            target_column=request.target_column,\n            group_by=request.group_by,\n            metrics=results['metrics'].model_dump(),\n            forecast_data=[f.model_dump() for f in results['forecast']],\n            historical_data=[h.model_dump() for h in results['historical']],\n            decomposition_data=results['decomposition'].model_dump() if results['decomposition'] else None,\n            feature_importance=[fi.model_dump() for fi in results['feature_importance']] if results['feature_importance'] else None,\n            top_products=top_products,\n            top_regions=top_regions\n        )\n        \n        update_job_status(request.job_id, 'completed')\n        \n        return ForecastResponse(\n            job_id=request.job_id,\n            model_type=request.model.value,\n            aggregation=request.aggregation.value,\n            horizon=request.horizon,\n            target_column=request.target_column,\n            metrics=results['metrics'],\n            forecast=[f.model_dump() for f in results['forecast']],\n            historical=[h.model_dump() for h in results['historical']],\n            decomposition=results['decomposition'],\n            feature_importance=results['feature_importance'],\n            top_products=top_products,\n            top_regions=top_regions\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Forecast error: {str(e)}\")\n        update_job_status(request.job_id, 'error')\n        raise HTTPException(status_code=500, detail=f\"Forecasting error: {str(e)}\")\n\n\n@router.get(\"/forecast/{job_id}\")\nasync def get_forecast(job_id: str):\n    forecast = get_latest_forecast(job_id)\n    if not forecast:\n        raise HTTPException(status_code=404, detail=\"No forecast found for this job\")\n    \n    return {\n        'job_id': job_id,\n        'model_type': forecast['model_type'],\n        'aggregation': forecast['aggregation'],\n        'horizon': forecast['horizon'],\n        'target_column': forecast['target_column'],\n        'metrics': forecast['metrics'],\n        'forecast': forecast['forecast_data'],\n        'historical': forecast['historical_data'],\n        'decomposition': forecast['decomposition_data'],\n        'feature_importance': forecast['feature_importance'],\n        'top_products': forecast['top_products'],\n        'top_regions': forecast['top_regions'],\n        'created_at': forecast['created_at']\n    }\n","path":null,"size_bytes":5318,"size_tokens":null},"AISalesForecaster/frontend/src/components/Dashboard.jsx":{"content":"import { useState } from 'react';\nimport { \n  LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, Legend, \n  ResponsiveContainer, AreaChart, Area, BarChart, Bar, ComposedChart\n} from 'recharts';\nimport { TrendingUp, Target, AlertCircle, Download, ChevronDown, ChevronUp } from 'lucide-react';\nimport { downloadReport } from '../services/api';\n\nfunction Dashboard({ forecastData, jobId }) {\n  const [showDecomposition, setShowDecomposition] = useState(false);\n  const { metrics, forecast, historical, decomposition, feature_importance, top_products, top_regions } = forecastData;\n\n  const combinedData = [\n    ...historical.map(h => ({\n      date: h.date,\n      actual: h.actual,\n      predicted: null,\n      lower: null,\n      upper: null,\n      type: 'historical'\n    })),\n    ...forecast.map(f => ({\n      date: f.date,\n      actual: null,\n      predicted: f.predicted,\n      lower: f.lower_bound,\n      upper: f.upper_bound,\n      type: 'forecast'\n    }))\n  ];\n\n  const handleDownload = async (format) => {\n    try {\n      await downloadReport(jobId, format);\n    } catch (err) {\n      console.error('Download failed:', err);\n    }\n  };\n\n  const formatNumber = (num) => {\n    if (num >= 1000000) return (num / 1000000).toFixed(1) + 'M';\n    if (num >= 1000) return (num / 1000).toFixed(1) + 'K';\n    return num?.toFixed(2);\n  };\n\n  return (\n    <div className=\"space-y-6\">\n      <div className=\"flex flex-wrap items-center justify-between gap-4\">\n        <div>\n          <h2 className=\"text-2xl font-bold text-gray-800\">Forecast Dashboard</h2>\n          <p className=\"text-gray-600\">\n            {forecastData.model_type.toUpperCase()} model | {forecastData.horizon} month forecast | {forecastData.aggregation} aggregation\n          </p>\n        </div>\n        <div className=\"flex gap-2\">\n          <button\n            onClick={() => handleDownload('csv')}\n            className=\"flex items-center gap-2 px-4 py-2 bg-white border border-gray-300 rounded-lg hover:bg-gray-50 transition-colors\"\n          >\n            <Download size={18} />\n            CSV\n          </button>\n          <button\n            onClick={() => handleDownload('pdf')}\n            className=\"flex items-center gap-2 px-4 py-2 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors\"\n          >\n            <Download size={18} />\n            PDF Report\n          </button>\n        </div>\n      </div>\n\n      <div className=\"grid md:grid-cols-4 gap-4\">\n        <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-4\">\n          <div className=\"flex items-center gap-2 text-gray-500 text-sm mb-1\">\n            <Target size={16} />\n            MAE\n          </div>\n          <p className=\"text-2xl font-bold text-gray-800\">{formatNumber(metrics.mae)}</p>\n          <p className=\"text-xs text-gray-500\">Mean Absolute Error</p>\n        </div>\n        <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-4\">\n          <div className=\"flex items-center gap-2 text-gray-500 text-sm mb-1\">\n            <TrendingUp size={16} />\n            RMSE\n          </div>\n          <p className=\"text-2xl font-bold text-gray-800\">{formatNumber(metrics.rmse)}</p>\n          <p className=\"text-xs text-gray-500\">Root Mean Squared Error</p>\n        </div>\n        <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-4\">\n          <div className=\"flex items-center gap-2 text-gray-500 text-sm mb-1\">\n            <AlertCircle size={16} />\n            MAPE\n          </div>\n          <p className=\"text-2xl font-bold text-gray-800\">{metrics.mape.toFixed(1)}%</p>\n          <p className=\"text-xs text-gray-500\">Mean Absolute % Error</p>\n        </div>\n        <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-4\">\n          <div className=\"flex items-center gap-2 text-gray-500 text-sm mb-1\">\n            Accuracy\n          </div>\n          <p className={`text-2xl font-bold ${\n            100 - metrics.mape >= 90 ? 'text-green-600' : \n            100 - metrics.mape >= 80 ? 'text-yellow-600' : 'text-red-600'\n          }`}>\n            {(100 - metrics.mape).toFixed(1)}%\n          </p>\n          <p className=\"text-xs text-gray-500\">Model Accuracy</p>\n        </div>\n      </div>\n\n      <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-6\">\n        <h3 className=\"text-lg font-semibold text-gray-800 mb-4\">Historical vs Forecast</h3>\n        <ResponsiveContainer width=\"100%\" height={400}>\n          <ComposedChart data={combinedData}>\n            <CartesianGrid strokeDasharray=\"3 3\" stroke=\"#e5e7eb\" />\n            <XAxis \n              dataKey=\"date\" \n              tick={{ fontSize: 12 }}\n              tickFormatter={(value) => {\n                const date = new Date(value);\n                return date.toLocaleDateString('en-US', { month: 'short', year: '2-digit' });\n              }}\n            />\n            <YAxis \n              tick={{ fontSize: 12 }}\n              tickFormatter={formatNumber}\n            />\n            <Tooltip\n              formatter={(value, name) => [formatNumber(value), name]}\n              labelFormatter={(label) => new Date(label).toLocaleDateString()}\n            />\n            <Legend />\n            <Area\n              dataKey=\"upper\"\n              stroke=\"none\"\n              fill=\"#93c5fd\"\n              fillOpacity={0.3}\n              name=\"Upper Bound\"\n            />\n            <Area\n              dataKey=\"lower\"\n              stroke=\"none\"\n              fill=\"#ffffff\"\n              fillOpacity={1}\n              name=\"Lower Bound\"\n            />\n            <Line\n              type=\"monotone\"\n              dataKey=\"actual\"\n              stroke=\"#1e40af\"\n              strokeWidth={2}\n              dot={false}\n              name=\"Actual\"\n            />\n            <Line\n              type=\"monotone\"\n              dataKey=\"predicted\"\n              stroke=\"#7c3aed\"\n              strokeWidth={2}\n              strokeDasharray=\"5 5\"\n              dot={false}\n              name=\"Forecast\"\n            />\n          </ComposedChart>\n        </ResponsiveContainer>\n      </div>\n\n      {decomposition && (\n        <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden\">\n          <button\n            onClick={() => setShowDecomposition(!showDecomposition)}\n            className=\"w-full flex items-center justify-between p-4 hover:bg-gray-50 transition-colors\"\n          >\n            <h3 className=\"text-lg font-semibold text-gray-800\">Time Series Decomposition</h3>\n            {showDecomposition ? <ChevronUp size={20} /> : <ChevronDown size={20} />}\n          </button>\n          \n          {showDecomposition && (\n            <div className=\"p-6 pt-0 space-y-4\">\n              <div>\n                <h4 className=\"text-sm font-medium text-gray-600 mb-2\">Trend</h4>\n                <ResponsiveContainer width=\"100%\" height={150}>\n                  <LineChart data={decomposition.trend}>\n                    <CartesianGrid strokeDasharray=\"3 3\" stroke=\"#e5e7eb\" />\n                    <XAxis dataKey=\"date\" tick={{ fontSize: 10 }} />\n                    <YAxis tick={{ fontSize: 10 }} tickFormatter={formatNumber} />\n                    <Tooltip formatter={(value) => formatNumber(value)} />\n                    <Line type=\"monotone\" dataKey=\"value\" stroke=\"#1e40af\" dot={false} />\n                  </LineChart>\n                </ResponsiveContainer>\n              </div>\n              <div>\n                <h4 className=\"text-sm font-medium text-gray-600 mb-2\">Seasonality</h4>\n                <ResponsiveContainer width=\"100%\" height={150}>\n                  <AreaChart data={decomposition.seasonal}>\n                    <CartesianGrid strokeDasharray=\"3 3\" stroke=\"#e5e7eb\" />\n                    <XAxis dataKey=\"date\" tick={{ fontSize: 10 }} />\n                    <YAxis tick={{ fontSize: 10 }} tickFormatter={formatNumber} />\n                    <Tooltip formatter={(value) => formatNumber(value)} />\n                    <Area type=\"monotone\" dataKey=\"value\" stroke=\"#7c3aed\" fill=\"#c4b5fd\" />\n                  </AreaChart>\n                </ResponsiveContainer>\n              </div>\n            </div>\n          )}\n        </div>\n      )}\n\n      {feature_importance && feature_importance.length > 0 && (\n        <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-6\">\n          <h3 className=\"text-lg font-semibold text-gray-800 mb-4\">Feature Importance</h3>\n          <ResponsiveContainer width=\"100%\" height={300}>\n            <BarChart data={feature_importance} layout=\"vertical\">\n              <CartesianGrid strokeDasharray=\"3 3\" stroke=\"#e5e7eb\" />\n              <XAxis type=\"number\" tick={{ fontSize: 12 }} />\n              <YAxis \n                dataKey=\"feature\" \n                type=\"category\" \n                tick={{ fontSize: 11 }}\n                width={120}\n              />\n              <Tooltip formatter={(value) => `${value.toFixed(1)}%`} />\n              <Bar dataKey=\"importance\" fill=\"#1e40af\" radius={[0, 4, 4, 0]} />\n            </BarChart>\n          </ResponsiveContainer>\n        </div>\n      )}\n\n      <div className=\"grid md:grid-cols-2 gap-6\">\n        {top_products && top_products.length > 0 && (\n          <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-6\">\n            <h3 className=\"text-lg font-semibold text-gray-800 mb-4\">Top Products</h3>\n            <div className=\"space-y-3\">\n              {top_products.map((product, idx) => (\n                <div key={idx} className=\"flex items-center justify-between p-3 bg-gray-50 rounded-lg\">\n                  <div className=\"flex items-center gap-3\">\n                    <span className=\"w-6 h-6 flex items-center justify-center bg-blue-100 text-blue-700 text-sm font-bold rounded\">\n                      {idx + 1}\n                    </span>\n                    <span className=\"font-medium text-gray-800\">\n                      {product.product_name || product.product_id}\n                    </span>\n                  </div>\n                  <span className=\"font-semibold text-gray-600\">\n                    ${formatNumber(product[forecastData.target_column])}\n                  </span>\n                </div>\n              ))}\n            </div>\n          </div>\n        )}\n\n        {top_regions && top_regions.length > 0 && (\n          <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 p-6\">\n            <h3 className=\"text-lg font-semibold text-gray-800 mb-4\">Top Regions</h3>\n            <ResponsiveContainer width=\"100%\" height={200}>\n              <BarChart data={top_regions}>\n                <CartesianGrid strokeDasharray=\"3 3\" stroke=\"#e5e7eb\" />\n                <XAxis dataKey=\"region\" tick={{ fontSize: 12 }} />\n                <YAxis tick={{ fontSize: 12 }} tickFormatter={formatNumber} />\n                <Tooltip formatter={(value) => formatNumber(value)} />\n                <Bar dataKey={forecastData.target_column} fill=\"#7c3aed\" radius={[4, 4, 0, 0]} />\n              </BarChart>\n            </ResponsiveContainer>\n          </div>\n        )}\n      </div>\n    </div>\n  );\n}\n\nexport default Dashboard;\n","path":null,"size_bytes":11133,"size_tokens":null},"AISalesForecaster/backend/generate_demo_data.py":{"content":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport random\nimport os\n\nnp.random.seed(42)\nrandom.seed(42)\n\nPRODUCTS = [\n    {\"id\": f\"SKU{str(i).zfill(3)}\", \"name\": f\"Product {chr(65 + i // 10)}{i % 10}\", \n     \"base_price\": round(random.uniform(10, 500), 2),\n     \"category\": random.choice([\"Electronics\", \"Clothing\", \"Home\", \"Sports\", \"Food\"])}\n    for i in range(50)\n]\n\nREGIONS = [\"North\", \"South\", \"East\", \"West\"]\n\nSEASONALITY = {\n    1: 0.85,\n    2: 0.80,\n    3: 0.90,\n    4: 0.95,\n    5: 1.00,\n    6: 1.05,\n    7: 1.10,\n    8: 1.05,\n    9: 0.95,\n    10: 1.00,\n    11: 1.20,\n    12: 1.40,\n}\n\nHOLIDAYS = [\n    (1, 1),\n    (2, 14),\n    (5, 28),\n    (7, 4),\n    (9, 4),\n    (11, 24),\n    (11, 25),\n    (12, 24),\n    (12, 25),\n    (12, 31),\n]\n\n\ndef generate_demo_data(\n    start_date: str = \"2022-01-01\",\n    end_date: str = \"2023-12-31\",\n    output_path: str = \"backend/data/demo_sales.csv\"\n):\n    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n    \n    date_range = pd.date_range(start=start, end=end, freq='D')\n    \n    records = []\n    \n    base_trend = 0\n    trend_growth = 0.0005\n    \n    for current_date in date_range:\n        base_trend += trend_growth\n        \n        seasonal_factor = SEASONALITY.get(current_date.month, 1.0)\n        \n        is_holiday = (current_date.month, current_date.day) in HOLIDAYS\n        holiday_boost = 1.3 if is_holiday else 1.0\n        \n        is_weekend = current_date.weekday() >= 5\n        weekend_factor = 1.15 if is_weekend else 1.0\n        \n        for product in PRODUCTS:\n            for region in REGIONS:\n                if random.random() > 0.7:\n                    continue\n                \n                base_units = random.randint(5, 50)\n                \n                units_sold = int(\n                    base_units \n                    * seasonal_factor \n                    * holiday_boost \n                    * weekend_factor \n                    * (1 + base_trend)\n                    * random.uniform(0.7, 1.3)\n                )\n                \n                promotion_flag = 0\n                price_discount = 1.0\n                \n                if random.random() < 0.15:\n                    promotion_flag = 1\n                    price_discount = random.uniform(0.8, 0.95)\n                    units_sold = int(units_sold * random.uniform(1.2, 1.5))\n                \n                if is_holiday and random.random() < 0.3:\n                    promotion_flag = 1\n                    price_discount = random.uniform(0.75, 0.9)\n                \n                price = round(product[\"base_price\"] * price_discount, 2)\n                \n                revenue = round(units_sold * price, 2)\n                \n                records.append({\n                    \"date\": current_date.strftime(\"%Y-%m-%d\"),\n                    \"product_id\": product[\"id\"],\n                    \"product_name\": product[\"name\"],\n                    \"region\": region,\n                    \"units_sold\": max(1, units_sold),\n                    \"revenue\": max(price, revenue),\n                    \"price\": price,\n                    \"promotion_flag\": promotion_flag,\n                })\n    \n    df = pd.DataFrame(records)\n    \n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    df.to_csv(output_path, index=False)\n    \n    print(f\"Generated {len(df):,} records\")\n    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n    print(f\"Products: {df['product_id'].nunique()}\")\n    print(f\"Regions: {df['region'].nunique()}\")\n    print(f\"Total revenue: ${df['revenue'].sum():,.2f}\")\n    print(f\"Saved to: {output_path}\")\n    \n    return df\n\n\ndef generate_simple_demo(output_path: str = \"backend/data/simple_demo.csv\"):\n    start = datetime.strptime(\"2022-01-01\", \"%Y-%m-%d\")\n    end = datetime.strptime(\"2023-12-31\", \"%Y-%m-%d\")\n    date_range = pd.date_range(start=start, end=end, freq='D')\n    \n    records = []\n    base_revenue = 10000\n    \n    for current_date in date_range:\n        seasonal = SEASONALITY.get(current_date.month, 1.0)\n        trend = 1 + (current_date - start).days * 0.0003\n        noise = random.uniform(0.85, 1.15)\n        \n        revenue = base_revenue * seasonal * trend * noise\n        units = int(revenue / 25)\n        \n        records.append({\n            \"date\": current_date.strftime(\"%Y-%m-%d\"),\n            \"product_id\": \"ALL\",\n            \"product_name\": \"All Products\",\n            \"region\": \"All Regions\",\n            \"units_sold\": units,\n            \"revenue\": round(revenue, 2),\n            \"price\": 25.00,\n            \"promotion_flag\": 1 if random.random() < 0.1 else 0,\n        })\n    \n    df = pd.DataFrame(records)\n    df.to_csv(output_path, index=False)\n    \n    print(f\"Generated simple demo with {len(df)} daily records\")\n    print(f\"Saved to: {output_path}\")\n    \n    return df\n\n\nif __name__ == \"__main__\":\n    print(\"Generating full demo dataset...\")\n    generate_demo_data()\n    \n    print(\"\\nGenerating simple demo dataset...\")\n    generate_simple_demo()\n","path":null,"size_bytes":5057,"size_tokens":null},"AISalesForecaster/frontend/src/components/Header.jsx":{"content":"import { BarChart3, RefreshCw } from 'lucide-react';\n\nfunction Header({ onReset, currentStep }) {\n  const steps = [\n    { id: 'upload', label: 'Upload' },\n    { id: 'preview', label: 'Preview' },\n    { id: 'config', label: 'Configure' },\n    { id: 'dashboard', label: 'Dashboard' },\n  ];\n\n  const currentIndex = steps.findIndex(s => s.id === currentStep);\n\n  return (\n    <header className=\"gradient-bg text-white shadow-lg\">\n      <div className=\"max-w-7xl mx-auto px-4 py-4\">\n        <div className=\"flex items-center justify-between\">\n          <div className=\"flex items-center gap-3\">\n            <div className=\"p-2 bg-white/20 rounded-lg\">\n              <BarChart3 size={28} />\n            </div>\n            <div>\n              <h1 className=\"text-xl font-bold\">AI Sales Forecaster</h1>\n              <p className=\"text-sm text-blue-100\">Business Insight Generator</p>\n            </div>\n          </div>\n          \n          <div className=\"hidden md:flex items-center gap-2\">\n            {steps.map((step, index) => (\n              <div key={step.id} className=\"flex items-center\">\n                <div className={`\n                  px-3 py-1 rounded-full text-sm font-medium\n                  ${index <= currentIndex ? 'bg-white/20' : 'bg-white/10 text-blue-200'}\n                `}>\n                  {step.label}\n                </div>\n                {index < steps.length - 1 && (\n                  <div className={`w-8 h-0.5 mx-1 ${index < currentIndex ? 'bg-white/40' : 'bg-white/20'}`} />\n                )}\n              </div>\n            ))}\n          </div>\n          \n          {currentStep !== 'upload' && (\n            <button\n              onClick={onReset}\n              className=\"flex items-center gap-2 px-4 py-2 bg-white/20 rounded-lg hover:bg-white/30 transition-colors\"\n            >\n              <RefreshCw size={18} />\n              <span className=\"hidden sm:inline\">Start Over</span>\n            </button>\n          )}\n        </div>\n      </div>\n    </header>\n  );\n}\n\nexport default Header;\n","path":null,"size_bytes":2031,"size_tokens":null},"AISalesForecaster/backend/app/services/forecaster.py":{"content":"import pandas as pd\nimport numpy as np\nfrom typing import Dict, List, Tuple, Optional, Any\nfrom datetime import datetime, timedelta\nimport logging\nimport warnings\n\nfrom prophet import Prophet\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\nfrom ..models.schemas import (\n    ModelType, AggregationType, ForecastMetrics, \n    ForecastPoint, DecompositionData, FeatureImportance\n)\n\nwarnings.filterwarnings('ignore')\nlogger = logging.getLogger(__name__)\n\n\nclass Forecaster:\n    def __init__(self, df: pd.DataFrame, target_column: str = 'revenue'):\n        self.df = df.copy()\n        self.target_column = target_column\n        self.model = None\n        self.model_type = None\n        self.metrics = None\n        self.feature_importance = None\n    \n    def _calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> ForecastMetrics:\n        mae = mean_absolute_error(y_true, y_pred)\n        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n        \n        with np.errstate(divide='ignore', invalid='ignore'):\n            mape = np.mean(np.abs((y_true - y_pred) / np.where(y_true == 0, 1, y_true))) * 100\n            mape = min(mape, 100.0)\n        \n        return ForecastMetrics(\n            mae=round(mae, 2),\n            rmse=round(rmse, 2),\n            mape=round(mape, 2),\n            train_size=len(y_true),\n            test_size=len(y_pred)\n        )\n    \n    def _get_forecast_periods(self, horizon: int, aggregation: AggregationType, \n                               last_date: datetime) -> pd.DatetimeIndex:\n        if aggregation == AggregationType.DAILY:\n            periods = horizon * 30\n            freq = 'D'\n        elif aggregation == AggregationType.WEEKLY:\n            periods = horizon * 4\n            freq = 'W'\n        else:\n            periods = horizon\n            freq = 'M'\n        \n        future_dates = pd.date_range(\n            start=last_date + timedelta(days=1),\n            periods=periods,\n            freq=freq\n        )\n        return future_dates\n    \n    def train_prophet(self, horizon: int = 6, \n                      aggregation: AggregationType = AggregationType.MONTHLY) -> Dict[str, Any]:\n        self.model_type = ModelType.PROPHET\n        \n        prophet_df = self.df[['date', self.target_column]].copy()\n        prophet_df.columns = ['ds', 'y']\n        prophet_df = prophet_df.dropna()\n        \n        train_size = int(len(prophet_df) * 0.8)\n        train_df = prophet_df.iloc[:train_size]\n        test_df = prophet_df.iloc[train_size:]\n        \n        self.model = Prophet(\n            yearly_seasonality=True,\n            weekly_seasonality=aggregation == AggregationType.DAILY,\n            daily_seasonality=False,\n            changepoint_prior_scale=0.05,\n            seasonality_prior_scale=10,\n            interval_width=0.95\n        )\n        \n        if 'promotion_flag' in self.df.columns:\n            self.model.add_regressor('promotion_flag')\n            train_df = train_df.merge(\n                self.df[['date', 'promotion_flag']].rename(columns={'date': 'ds'}),\n                on='ds', how='left'\n            ).fillna(0)\n        \n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            self.model.fit(train_df)\n        \n        test_forecast = self.model.predict(test_df[['ds']])\n        self.metrics = self._calculate_metrics(\n            test_df['y'].values, \n            test_forecast['yhat'].values\n        )\n        \n        future_dates = self._get_forecast_periods(horizon, aggregation, prophet_df['ds'].max())\n        future_df = pd.DataFrame({'ds': future_dates})\n        \n        if 'promotion_flag' in self.df.columns:\n            future_df['promotion_flag'] = 0\n        \n        forecast = self.model.predict(future_df)\n        \n        forecast_points = []\n        for _, row in forecast.iterrows():\n            forecast_points.append(ForecastPoint(\n                date=row['ds'].strftime('%Y-%m-%d'),\n                predicted=max(0, round(row['yhat'], 2)),\n                lower_bound=max(0, round(row['yhat_lower'], 2)),\n                upper_bound=round(row['yhat_upper'], 2)\n            ))\n        \n        historical_points = []\n        historical_forecast = self.model.predict(prophet_df[['ds']])\n        for (_, row), (_, hist_row) in zip(prophet_df.iterrows(), historical_forecast.iterrows()):\n            historical_points.append(ForecastPoint(\n                date=row['ds'].strftime('%Y-%m-%d'),\n                actual=round(row['y'], 2),\n                predicted=max(0, round(hist_row['yhat'], 2)),\n                lower_bound=max(0, round(hist_row['yhat_lower'], 2)),\n                upper_bound=round(hist_row['yhat_upper'], 2)\n            ))\n        \n        decomposition = self._extract_prophet_decomposition(prophet_df)\n        \n        return {\n            'forecast': forecast_points,\n            'historical': historical_points,\n            'metrics': self.metrics,\n            'decomposition': decomposition,\n            'feature_importance': None\n        }\n    \n    def _extract_prophet_decomposition(self, df: pd.DataFrame) -> DecompositionData:\n        forecast = self.model.predict(df[['ds']])\n        \n        trend_data = []\n        seasonal_data = []\n        residual_data = []\n        \n        for idx, row in forecast.iterrows():\n            date_str = row['ds'].strftime('%Y-%m-%d')\n            actual = df.iloc[idx]['y'] if idx < len(df) else None\n            \n            trend_data.append({\n                'date': date_str,\n                'value': round(row['trend'], 2)\n            })\n            \n            yearly_seasonal = row.get('yearly', 0)\n            weekly_seasonal = row.get('weekly', 0) if 'weekly' in row else 0\n            total_seasonal = yearly_seasonal + weekly_seasonal\n            \n            seasonal_data.append({\n                'date': date_str,\n                'value': round(total_seasonal, 2)\n            })\n            \n            if actual is not None:\n                residual = actual - row['yhat']\n                residual_data.append({\n                    'date': date_str,\n                    'value': round(residual, 2)\n                })\n        \n        return DecompositionData(\n            trend=trend_data,\n            seasonal=seasonal_data,\n            residual=residual_data\n        )\n    \n    def train_lightgbm(self, horizon: int = 6,\n                       aggregation: AggregationType = AggregationType.MONTHLY) -> Dict[str, Any]:\n        self.model_type = ModelType.LIGHTGBM\n        \n        df = self.df.copy()\n        df = df.sort_values('date')\n        \n        exclude_cols = ['date', self.target_column, 'holiday_name']\n        if 'product_id' in df.columns:\n            exclude_cols.append('product_id')\n        if 'product_name' in df.columns:\n            exclude_cols.append('product_name')\n        if 'region' in df.columns:\n            exclude_cols.append('region')\n        \n        feature_cols = [col for col in df.columns \n                       if col not in exclude_cols \n                       and df[col].dtype in ['int64', 'float64', 'int32', 'float32']]\n        \n        X = df[feature_cols].fillna(0)\n        y = df[self.target_column].fillna(0)\n        \n        train_size = int(len(df) * 0.8)\n        X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n        y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n        \n        params = {\n            'objective': 'regression',\n            'metric': 'rmse',\n            'boosting_type': 'gbdt',\n            'num_leaves': 31,\n            'learning_rate': 0.05,\n            'feature_fraction': 0.8,\n            'bagging_fraction': 0.8,\n            'bagging_freq': 5,\n            'verbose': -1,\n            'n_estimators': 100\n        }\n        \n        self.model = lgb.LGBMRegressor(**params)\n        self.model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n        \n        y_pred = self.model.predict(X_test)\n        self.metrics = self._calculate_metrics(y_test.values, y_pred)\n        \n        importances = self.model.feature_importances_\n        self.feature_importance = [\n            FeatureImportance(feature=feat, importance=round(imp / sum(importances) * 100, 2))\n            for feat, imp in sorted(zip(feature_cols, importances), \n                                   key=lambda x: x[1], reverse=True)[:10]\n        ]\n        \n        last_date = df['date'].max()\n        future_dates = self._get_forecast_periods(horizon, aggregation, last_date)\n        \n        last_row = df.iloc[-1].copy()\n        forecast_points = []\n        \n        for future_date in future_dates:\n            future_features = self._create_future_features(last_row, future_date, feature_cols)\n            prediction = max(0, self.model.predict([future_features])[0])\n            \n            std_dev = np.std(y) * 0.1\n            forecast_points.append(ForecastPoint(\n                date=future_date.strftime('%Y-%m-%d'),\n                predicted=round(prediction, 2),\n                lower_bound=max(0, round(prediction - 1.96 * std_dev, 2)),\n                upper_bound=round(prediction + 1.96 * std_dev, 2)\n            ))\n            \n            last_row[self.target_column] = prediction\n        \n        historical_points = []\n        y_hist_pred = self.model.predict(X)\n        \n        for idx, (_, row) in enumerate(df.iterrows()):\n            std_dev = np.std(y) * 0.1\n            historical_points.append(ForecastPoint(\n                date=row['date'].strftime('%Y-%m-%d'),\n                actual=round(row[self.target_column], 2),\n                predicted=max(0, round(y_hist_pred[idx], 2)),\n                lower_bound=max(0, round(y_hist_pred[idx] - 1.96 * std_dev, 2)),\n                upper_bound=round(y_hist_pred[idx] + 1.96 * std_dev, 2)\n            ))\n        \n        return {\n            'forecast': forecast_points,\n            'historical': historical_points,\n            'metrics': self.metrics,\n            'decomposition': None,\n            'feature_importance': self.feature_importance\n        }\n    \n    def _create_future_features(self, last_row: pd.Series, \n                                future_date: pd.Timestamp,\n                                feature_cols: List[str]) -> List[float]:\n        features = []\n        \n        for col in feature_cols:\n            if col == 'year':\n                features.append(future_date.year)\n            elif col == 'month':\n                features.append(future_date.month)\n            elif col == 'day':\n                features.append(future_date.day)\n            elif col == 'day_of_week':\n                features.append(future_date.dayofweek)\n            elif col == 'week_of_year':\n                features.append(future_date.isocalendar()[1])\n            elif col == 'quarter':\n                features.append((future_date.month - 1) // 3 + 1)\n            elif col == 'is_weekend':\n                features.append(1 if future_date.dayofweek >= 5 else 0)\n            elif col == 'is_month_start':\n                features.append(1 if future_date.day == 1 else 0)\n            elif col == 'is_month_end':\n                features.append(1 if future_date.day == future_date.days_in_month else 0)\n            elif col in last_row:\n                features.append(float(last_row[col]) if pd.notna(last_row[col]) else 0)\n            else:\n                features.append(0)\n        \n        return features\n    \n    def forecast(self, model_type: ModelType, horizon: int = 6,\n                 aggregation: AggregationType = AggregationType.MONTHLY) -> Dict[str, Any]:\n        if model_type == ModelType.PROPHET:\n            return self.train_prophet(horizon, aggregation)\n        else:\n            return self.train_lightgbm(horizon, aggregation)\n","path":null,"size_bytes":11819,"size_tokens":null},"AISalesForecaster/backend/app/routes/__init__.py":{"content":"from .upload import router as upload_router\nfrom .forecast import router as forecast_router\nfrom .insights import router as insights_router\nfrom .download import router as download_router\n","path":null,"size_bytes":188,"size_tokens":null},"AISalesForecaster/backend/tests/test_data_pipeline.py":{"content":"import pytest\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport sys\nimport os\n\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))\n\nfrom app.services.data_pipeline import DataPipeline\nfrom app.models.schemas import AggregationType\n\n\ndef create_sample_df(n_rows=100):\n    dates = pd.date_range(start='2023-01-01', periods=n_rows, freq='D')\n    return pd.DataFrame({\n        'date': dates,\n        'product_id': ['SKU001'] * n_rows,\n        'product_name': ['Product A'] * n_rows,\n        'region': np.random.choice(['North', 'South', 'East', 'West'], n_rows),\n        'units_sold': np.random.randint(10, 100, n_rows),\n        'revenue': np.random.uniform(100, 1000, n_rows).round(2),\n        'price': np.random.uniform(10, 50, n_rows).round(2),\n        'promotion_flag': np.random.choice([0, 1], n_rows, p=[0.8, 0.2])\n    })\n\n\nclass TestDataPipeline:\n    def test_validate_valid_data(self):\n        df = create_sample_df()\n        pipeline = DataPipeline(df)\n        result = pipeline.validate()\n        \n        assert result.is_valid == True\n        assert len(result.errors) == 0\n        assert result.row_count == 100\n        assert result.column_count == 8\n    \n    def test_validate_missing_date_column(self):\n        df = create_sample_df()\n        df = df.drop(columns=['date'])\n        pipeline = DataPipeline(df)\n        result = pipeline.validate()\n        \n        assert result.is_valid == False\n        assert any('date' in err.lower() for err in result.errors)\n    \n    def test_validate_date_range(self):\n        df = create_sample_df()\n        pipeline = DataPipeline(df)\n        result = pipeline.validate()\n        \n        assert result.date_range is not None\n        assert 'start' in result.date_range\n        assert 'end' in result.date_range\n    \n    def test_clean_data(self):\n        df = create_sample_df()\n        df.loc[0, 'revenue'] = np.nan\n        df.loc[1, 'units_sold'] = np.nan\n        \n        pipeline = DataPipeline(df)\n        cleaned = pipeline.clean_data()\n        \n        assert cleaned['revenue'].isna().sum() == 0\n        assert cleaned['units_sold'].isna().sum() == 0\n    \n    def test_handle_outliers(self):\n        df = create_sample_df()\n        df.loc[0, 'revenue'] = 1000000\n        \n        pipeline = DataPipeline(df)\n        pipeline.clean_data()\n        result = pipeline.handle_outliers(['revenue'])\n        \n        assert result['revenue'].max() < 1000000\n    \n    def test_aggregate_monthly(self):\n        df = create_sample_df(n_rows=365)\n        pipeline = DataPipeline(df)\n        \n        aggregated = pipeline.aggregate(AggregationType.MONTHLY, 'revenue')\n        \n        assert len(aggregated) <= 12\n        assert 'date' in aggregated.columns\n        assert 'revenue' in aggregated.columns\n    \n    def test_aggregate_weekly(self):\n        df = create_sample_df(n_rows=100)\n        pipeline = DataPipeline(df)\n        \n        aggregated = pipeline.aggregate(AggregationType.WEEKLY, 'revenue')\n        \n        assert len(aggregated) <= 15\n        assert 'date' in aggregated.columns\n    \n    def test_engineer_features(self):\n        df = create_sample_df()\n        pipeline = DataPipeline(df)\n        aggregated = pipeline.aggregate(AggregationType.DAILY, 'revenue')\n        featured = pipeline.engineer_features(aggregated, 'revenue')\n        \n        assert 'year' in featured.columns\n        assert 'month' in featured.columns\n        assert 'day_of_week' in featured.columns\n        assert 'revenue_lag_1' in featured.columns\n        assert 'revenue_rolling_mean_7' in featured.columns\n    \n    def test_get_preview(self):\n        df = create_sample_df()\n        pipeline = DataPipeline(df)\n        preview = pipeline.get_preview(n=5)\n        \n        assert len(preview) == 5\n        assert isinstance(preview, list)\n        assert isinstance(preview[0], dict)\n    \n    def test_get_column_info(self):\n        df = create_sample_df()\n        pipeline = DataPipeline(df)\n        all_cols, numeric_cols, categorical_cols = pipeline.get_column_info()\n        \n        assert 'revenue' in numeric_cols\n        assert 'units_sold' in numeric_cols\n        assert 'region' in categorical_cols\n    \n    def test_prepare_for_modeling(self):\n        df = create_sample_df(n_rows=100)\n        pipeline = DataPipeline(df)\n        result = pipeline.prepare_for_modeling(\n            aggregation=AggregationType.DAILY,\n            target_column='revenue'\n        )\n        \n        assert 'date' in result.columns\n        assert 'revenue' in result.columns\n        assert len(result) > 0\n\n\nclass TestDataPipelineEdgeCases:\n    def test_empty_dataframe(self):\n        df = pd.DataFrame()\n        pipeline = DataPipeline(df)\n        result = pipeline.validate()\n        \n        assert result.row_count == 0\n    \n    def test_single_row(self):\n        df = create_sample_df(n_rows=1)\n        pipeline = DataPipeline(df)\n        result = pipeline.validate()\n        \n        assert result.is_valid == True\n        assert result.row_count == 1\n    \n    def test_missing_numeric_columns(self):\n        df = pd.DataFrame({\n            'date': pd.date_range(start='2023-01-01', periods=10),\n            'category': ['A'] * 10\n        })\n        pipeline = DataPipeline(df)\n        result = pipeline.validate()\n        \n        assert any('numeric' in w.lower() for w in result.warnings)\n\n\nif __name__ == '__main__':\n    pytest.main([__file__, '-v'])\n","path":null,"size_bytes":5453,"size_tokens":null},"AISalesForecaster/frontend/src/components/LoadingOverlay.jsx":{"content":"import { Loader2, BarChart3 } from 'lucide-react';\n\nfunction LoadingOverlay({ message = 'Processing...' }) {\n  return (\n    <div className=\"fixed inset-0 bg-black/50 backdrop-blur-sm z-50 flex items-center justify-center\">\n      <div className=\"bg-white rounded-2xl p-8 shadow-2xl max-w-sm w-full mx-4 text-center\">\n        <div className=\"relative w-20 h-20 mx-auto mb-4\">\n          <div className=\"absolute inset-0 bg-blue-100 rounded-full animate-ping opacity-75\"></div>\n          <div className=\"relative flex items-center justify-center w-20 h-20 bg-gradient-to-br from-blue-500 to-purple-600 rounded-full\">\n            <BarChart3 size={32} className=\"text-white\" />\n          </div>\n        </div>\n        \n        <div className=\"flex items-center justify-center gap-2 mb-2\">\n          <Loader2 size={20} className=\"animate-spin text-blue-600\" />\n          <span className=\"text-lg font-semibold text-gray-800\">Please Wait</span>\n        </div>\n        \n        <p className=\"text-gray-600\">{message}</p>\n        \n        <div className=\"mt-4 h-1 bg-gray-100 rounded-full overflow-hidden\">\n          <div className=\"h-full bg-gradient-to-r from-blue-500 to-purple-600 rounded-full animate-pulse-slow w-2/3\"></div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nexport default LoadingOverlay;\n","path":null,"size_bytes":1299,"size_tokens":null},"AISalesForecaster/backend/app/routes/insights.py":{"content":"import os\nimport pandas as pd\nfrom fastapi import APIRouter, HTTPException, Query\nimport logging\n\nfrom ..models.schemas import InsightsResponse, ForecastMetrics, FeatureImportance\nfrom ..models.database import (\n    get_job, get_latest_forecast, save_insights, get_latest_insights\n)\nfrom ..services.insights_generator import InsightsGenerator\n\nrouter = APIRouter()\nlogger = logging.getLogger(__name__)\n\n\n@router.get(\"/insights\", response_model=InsightsResponse)\nasync def get_insights(job_id: str = Query(..., description=\"Job ID from forecast\")):\n    job = get_job(job_id)\n    if not job:\n        raise HTTPException(status_code=404, detail=\"Job not found\")\n    \n    forecast = get_latest_forecast(job_id)\n    if not forecast:\n        raise HTTPException(\n            status_code=404, \n            detail=\"No forecast found. Please run a forecast first.\"\n        )\n    \n    try:\n        existing_insights = get_latest_insights(job_id)\n        if existing_insights:\n            return InsightsResponse(\n                job_id=job_id,\n                title=existing_insights['title'],\n                summary=existing_insights['summary'],\n                kpis=existing_insights['kpis'],\n                bullets=existing_insights['bullets'],\n                recommendations=existing_insights['recommendations'],\n                generated_at=existing_insights['created_at']\n            )\n        \n        df = pd.read_csv(job['file_path'])\n        df['date'] = pd.to_datetime(df['date'])\n        \n        if 'month' not in df.columns:\n            df['month'] = df['date'].dt.month\n        \n        metrics = ForecastMetrics(**forecast['metrics'])\n        \n        feature_importance = None\n        if forecast['feature_importance']:\n            feature_importance = [\n                FeatureImportance(**fi) for fi in forecast['feature_importance']\n            ]\n        \n        generator = InsightsGenerator(\n            historical_df=df,\n            forecast_data=forecast['forecast_data'],\n            metrics=metrics,\n            target_column=forecast['target_column'],\n            feature_importance=feature_importance\n        )\n        \n        insights = generator.generate_insights()\n        \n        save_insights(\n            job_id=job_id,\n            title=insights['title'],\n            summary=insights['summary'],\n            kpis=insights['kpis'],\n            bullets=insights['bullets'],\n            recommendations=insights['recommendations']\n        )\n        \n        return InsightsResponse(\n            job_id=job_id,\n            **insights\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(f\"Insights generation error: {str(e)}\")\n        raise HTTPException(status_code=500, detail=f\"Error generating insights: {str(e)}\")\n\n\n@router.post(\"/insights/regenerate\")\nasync def regenerate_insights(job_id: str = Query(...)):\n    job = get_job(job_id)\n    if not job:\n        raise HTTPException(status_code=404, detail=\"Job not found\")\n    \n    forecast = get_latest_forecast(job_id)\n    if not forecast:\n        raise HTTPException(status_code=404, detail=\"No forecast found\")\n    \n    try:\n        df = pd.read_csv(job['file_path'])\n        df['date'] = pd.to_datetime(df['date'])\n        \n        if 'month' not in df.columns:\n            df['month'] = df['date'].dt.month\n        \n        metrics = ForecastMetrics(**forecast['metrics'])\n        \n        feature_importance = None\n        if forecast['feature_importance']:\n            feature_importance = [\n                FeatureImportance(**fi) for fi in forecast['feature_importance']\n            ]\n        \n        generator = InsightsGenerator(\n            historical_df=df,\n            forecast_data=forecast['forecast_data'],\n            metrics=metrics,\n            target_column=forecast['target_column'],\n            feature_importance=feature_importance\n        )\n        \n        insights = generator.generate_insights()\n        \n        save_insights(\n            job_id=job_id,\n            title=insights['title'],\n            summary=insights['summary'],\n            kpis=insights['kpis'],\n            bullets=insights['bullets'],\n            recommendations=insights['recommendations']\n        )\n        \n        return InsightsResponse(\n            job_id=job_id,\n            **insights\n        )\n        \n    except Exception as e:\n        logger.error(f\"Insights regeneration error: {str(e)}\")\n        raise HTTPException(status_code=500, detail=f\"Error regenerating insights: {str(e)}\")\n","path":null,"size_bytes":4535,"size_tokens":null},"AISalesForecaster/frontend/src/main.jsx":{"content":"import { StrictMode } from 'react'\nimport { createRoot } from 'react-dom/client'\nimport './index.css'\nimport App from './App.jsx'\n\ncreateRoot(document.getElementById('root')).render(\n  <StrictMode>\n    <App />\n  </StrictMode>,\n)\n","path":null,"size_bytes":229,"size_tokens":null},"AISalesForecaster/backend/tests/test_forecaster.py":{"content":"import pytest\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport sys\nimport os\n\nsys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))\n\nfrom app.services.forecaster import Forecaster\nfrom app.services.data_pipeline import DataPipeline\nfrom app.models.schemas import ModelType, AggregationType\n\n\ndef create_forecast_ready_df(n_rows=365):\n    dates = pd.date_range(start='2023-01-01', periods=n_rows, freq='D')\n    \n    base_revenue = 1000\n    seasonal = np.sin(np.linspace(0, 4*np.pi, n_rows)) * 200\n    trend = np.linspace(0, 200, n_rows)\n    noise = np.random.normal(0, 50, n_rows)\n    \n    revenue = base_revenue + seasonal + trend + noise\n    revenue = np.maximum(revenue, 100)\n    \n    df = pd.DataFrame({\n        'date': dates,\n        'revenue': revenue.round(2),\n        'units_sold': (revenue / 25).astype(int),\n        'price': 25.0,\n        'promotion_flag': np.random.choice([0, 1], n_rows, p=[0.85, 0.15])\n    })\n    \n    pipeline = DataPipeline(df)\n    return pipeline.prepare_for_modeling(\n        aggregation=AggregationType.DAILY,\n        target_column='revenue'\n    )\n\n\nclass TestForecaster:\n    @pytest.fixture\n    def sample_df(self):\n        return create_forecast_ready_df(n_rows=200)\n    \n    def test_forecaster_initialization(self, sample_df):\n        forecaster = Forecaster(sample_df, 'revenue')\n        \n        assert forecaster.df is not None\n        assert forecaster.target_column == 'revenue'\n        assert forecaster.model is None\n    \n    def test_prophet_forecast(self, sample_df):\n        forecaster = Forecaster(sample_df, 'revenue')\n        results = forecaster.train_prophet(horizon=3, aggregation=AggregationType.DAILY)\n        \n        assert 'forecast' in results\n        assert 'historical' in results\n        assert 'metrics' in results\n        assert len(results['forecast']) > 0\n        \n        assert results['metrics'].mae > 0\n        assert results['metrics'].rmse > 0\n        assert 0 <= results['metrics'].mape <= 100\n    \n    def test_lightgbm_forecast(self, sample_df):\n        forecaster = Forecaster(sample_df, 'revenue')\n        results = forecaster.train_lightgbm(horizon=3, aggregation=AggregationType.DAILY)\n        \n        assert 'forecast' in results\n        assert 'historical' in results\n        assert 'metrics' in results\n        assert 'feature_importance' in results\n        assert len(results['forecast']) > 0\n    \n    def test_forecast_with_model_type(self, sample_df):\n        forecaster = Forecaster(sample_df, 'revenue')\n        \n        prophet_results = forecaster.forecast(\n            model_type=ModelType.PROPHET,\n            horizon=3,\n            aggregation=AggregationType.DAILY\n        )\n        \n        assert prophet_results is not None\n        assert len(prophet_results['forecast']) > 0\n    \n    def test_forecast_points_structure(self, sample_df):\n        forecaster = Forecaster(sample_df, 'revenue')\n        results = forecaster.train_prophet(horizon=3, aggregation=AggregationType.DAILY)\n        \n        forecast_point = results['forecast'][0]\n        assert hasattr(forecast_point, 'date')\n        assert hasattr(forecast_point, 'predicted')\n        assert hasattr(forecast_point, 'lower_bound')\n        assert hasattr(forecast_point, 'upper_bound')\n    \n    def test_historical_points_have_actuals(self, sample_df):\n        forecaster = Forecaster(sample_df, 'revenue')\n        results = forecaster.train_prophet(horizon=3, aggregation=AggregationType.DAILY)\n        \n        hist_point = results['historical'][0]\n        assert hasattr(hist_point, 'actual')\n        assert hist_point.actual is not None\n    \n    def test_metrics_calculation(self, sample_df):\n        forecaster = Forecaster(sample_df, 'revenue')\n        results = forecaster.train_prophet(horizon=3, aggregation=AggregationType.DAILY)\n        \n        metrics = results['metrics']\n        assert metrics.train_size > 0\n        assert metrics.test_size > 0\n        assert metrics.mae >= 0\n        assert metrics.rmse >= 0\n    \n    def test_decomposition_for_prophet(self, sample_df):\n        forecaster = Forecaster(sample_df, 'revenue')\n        results = forecaster.train_prophet(horizon=3, aggregation=AggregationType.DAILY)\n        \n        assert results['decomposition'] is not None\n        assert len(results['decomposition'].trend) > 0\n        assert len(results['decomposition'].seasonal) > 0\n    \n    def test_feature_importance_for_lightgbm(self, sample_df):\n        forecaster = Forecaster(sample_df, 'revenue')\n        results = forecaster.train_lightgbm(horizon=3, aggregation=AggregationType.DAILY)\n        \n        assert results['feature_importance'] is not None\n        assert len(results['feature_importance']) > 0\n        \n        fi = results['feature_importance'][0]\n        assert hasattr(fi, 'feature')\n        assert hasattr(fi, 'importance')\n\n\nclass TestForecasterEdgeCases:\n    def test_small_dataset(self):\n        df = create_forecast_ready_df(n_rows=50)\n        forecaster = Forecaster(df, 'revenue')\n        \n        results = forecaster.train_prophet(horizon=1, aggregation=AggregationType.DAILY)\n        assert results is not None\n    \n    def test_forecast_values_positive(self):\n        df = create_forecast_ready_df(n_rows=200)\n        forecaster = Forecaster(df, 'revenue')\n        results = forecaster.train_prophet(horizon=3, aggregation=AggregationType.DAILY)\n        \n        for point in results['forecast']:\n            assert point.predicted >= 0\n\n\nif __name__ == '__main__':\n    pytest.main([__file__, '-v'])\n","path":null,"size_bytes":5553,"size_tokens":null},"AISalesForecaster/backend/app/utils/holidays.py":{"content":"import pandas as pd\nfrom datetime import datetime, date\nfrom typing import List, Dict\n\nUS_HOLIDAYS = {\n    (1, 1): \"New Year's Day\",\n    (7, 4): \"Independence Day\",\n    (12, 25): \"Christmas Day\",\n    (11, 11): \"Veterans Day\",\n    (12, 31): \"New Year's Eve\",\n}\n\nFLOATING_HOLIDAYS = [\n    {\"name\": \"Martin Luther King Jr. Day\", \"month\": 1, \"week\": 3, \"weekday\": 0},\n    {\"name\": \"Presidents Day\", \"month\": 2, \"week\": 3, \"weekday\": 0},\n    {\"name\": \"Memorial Day\", \"month\": 5, \"week\": -1, \"weekday\": 0},\n    {\"name\": \"Labor Day\", \"month\": 9, \"week\": 1, \"weekday\": 0},\n    {\"name\": \"Thanksgiving\", \"month\": 11, \"week\": 4, \"weekday\": 3},\n    {\"name\": \"Black Friday\", \"month\": 11, \"week\": 4, \"weekday\": 4},\n]\n\n\ndef get_nth_weekday_of_month(year: int, month: int, weekday: int, n: int) -> date:\n    if n > 0:\n        first_day = date(year, month, 1)\n        first_weekday = first_day.weekday()\n        days_until = (weekday - first_weekday) % 7\n        first_occurrence = first_day.replace(day=1 + days_until)\n        return first_occurrence.replace(day=first_occurrence.day + (n - 1) * 7)\n    else:\n        if month == 12:\n            next_month = date(year + 1, 1, 1)\n        else:\n            next_month = date(year, month + 1, 1)\n        last_day = (next_month - pd.Timedelta(days=1)).day\n        last_date = date(year, month, last_day)\n        last_weekday = last_date.weekday()\n        days_back = (last_weekday - weekday) % 7\n        return last_date.replace(day=last_date.day - days_back)\n\n\ndef get_holidays_for_year(year: int) -> Dict[date, str]:\n    holidays = {}\n    \n    for (month, day), name in US_HOLIDAYS.items():\n        try:\n            holidays[date(year, month, day)] = name\n        except ValueError:\n            pass\n    \n    for holiday in FLOATING_HOLIDAYS:\n        try:\n            holiday_date = get_nth_weekday_of_month(\n                year, holiday[\"month\"], holiday[\"weekday\"], holiday[\"week\"]\n            )\n            holidays[holiday_date] = holiday[\"name\"]\n        except (ValueError, AttributeError):\n            pass\n    \n    return holidays\n\n\ndef get_holiday_flags(dates: pd.Series) -> pd.DataFrame:\n    dates = pd.to_datetime(dates)\n    years = dates.dt.year.unique()\n    \n    all_holidays = {}\n    for year in years:\n        all_holidays.update(get_holidays_for_year(year))\n    \n    result = pd.DataFrame({\n        'date': dates,\n        'is_holiday': dates.dt.date.isin(all_holidays.keys()).astype(int),\n        'holiday_name': dates.dt.date.map(lambda x: all_holidays.get(x, ''))\n    })\n    \n    result['days_to_holiday'] = 0\n    result['days_from_holiday'] = 0\n    \n    holiday_dates = sorted(all_holidays.keys())\n    \n    for idx, row in result.iterrows():\n        current_date = row['date'].date()\n        \n        future_holidays = [h for h in holiday_dates if h > current_date]\n        if future_holidays:\n            result.at[idx, 'days_to_holiday'] = (future_holidays[0] - current_date).days\n        \n        past_holidays = [h for h in holiday_dates if h < current_date]\n        if past_holidays:\n            result.at[idx, 'days_from_holiday'] = (current_date - past_holidays[-1]).days\n    \n    return result[['is_holiday', 'holiday_name', 'days_to_holiday', 'days_from_holiday']]\n","path":null,"size_bytes":3225,"size_tokens":null},"AISalesForecaster/pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"aiofiles>=25.1.0\",\n    \"fastapi>=0.122.0\",\n    \"lightgbm>=4.6.0\",\n    \"numpy>=2.3.5\",\n    \"pandas>=2.3.3\",\n    \"prophet>=1.2.1\",\n    \"pydantic>=2.12.5\",\n    \"pytest>=9.0.1\",\n    \"python-multipart>=0.0.20\",\n    \"reportlab>=4.4.5\",\n    \"scikit-learn>=1.7.2\",\n    \"uvicorn>=0.38.0\",\n]\n","path":null,"size_bytes":429,"size_tokens":null},"AISalesForecaster/frontend/src/App.jsx":{"content":"import { useState } from 'react';\nimport Header from './components/Header';\nimport FileUpload from './components/FileUpload';\nimport DataPreview from './components/DataPreview';\nimport ForecastConfig from './components/ForecastConfig';\nimport Dashboard from './components/Dashboard';\nimport InsightsCard from './components/InsightsCard';\nimport LoadingOverlay from './components/LoadingOverlay';\n\nfunction App() {\n  const [step, setStep] = useState('upload');\n  const [uploadData, setUploadData] = useState(null);\n  const [forecastData, setForecastData] = useState(null);\n  const [insightsData, setInsightsData] = useState(null);\n  const [loading, setLoading] = useState(false);\n  const [loadingMessage, setLoadingMessage] = useState('');\n  const [error, setError] = useState(null);\n\n  const handleUploadSuccess = (data) => {\n    setUploadData(data);\n    setError(null);\n    setStep('preview');\n  };\n\n  const handleConfigComplete = (forecast, insights) => {\n    setForecastData(forecast);\n    setInsightsData(insights);\n    setStep('dashboard');\n  };\n\n  const handleReset = () => {\n    setStep('upload');\n    setUploadData(null);\n    setForecastData(null);\n    setInsightsData(null);\n    setError(null);\n  };\n\n  return (\n    <div className=\"min-h-screen bg-slate-50\">\n      <Header onReset={handleReset} currentStep={step} />\n      \n      {loading && <LoadingOverlay message={loadingMessage} />}\n      \n      {error && (\n        <div className=\"max-w-4xl mx-auto px-4 py-4\">\n          <div className=\"bg-red-50 border border-red-200 rounded-lg p-4 text-red-700\">\n            {error}\n          </div>\n        </div>\n      )}\n      \n      <main className=\"max-w-7xl mx-auto px-4 py-8\">\n        {step === 'upload' && (\n          <FileUpload \n            onUploadSuccess={handleUploadSuccess}\n            setLoading={setLoading}\n            setLoadingMessage={setLoadingMessage}\n            setError={setError}\n          />\n        )}\n        \n        {step === 'preview' && uploadData && (\n          <div className=\"space-y-6\">\n            <DataPreview data={uploadData} />\n            <div className=\"flex justify-center\">\n              <button\n                onClick={() => setStep('config')}\n                className=\"px-8 py-3 bg-blue-600 text-white rounded-lg font-semibold hover:bg-blue-700 transition-colors\"\n              >\n                Continue to Forecast Configuration\n              </button>\n            </div>\n          </div>\n        )}\n        \n        {step === 'config' && uploadData && (\n          <ForecastConfig\n            uploadData={uploadData}\n            onComplete={handleConfigComplete}\n            setLoading={setLoading}\n            setLoadingMessage={setLoadingMessage}\n            setError={setError}\n            onBack={() => setStep('preview')}\n          />\n        )}\n        \n        {step === 'dashboard' && forecastData && (\n          <div className=\"space-y-6\">\n            <Dashboard \n              forecastData={forecastData} \n              jobId={uploadData?.job_id}\n            />\n            {insightsData && (\n              <InsightsCard \n                insights={insightsData} \n                jobId={uploadData?.job_id}\n              />\n            )}\n          </div>\n        )}\n      </main>\n    </div>\n  );\n}\n\nexport default App;\n","path":null,"size_bytes":3282,"size_tokens":null},"AISalesForecaster/frontend/src/components/InsightsCard.jsx":{"content":"import { \n  Lightbulb, TrendingUp, TrendingDown, Minus, \n  CheckCircle, AlertTriangle, Info, Download,\n  DollarSign, Calendar, Package, Zap\n} from 'lucide-react';\nimport { downloadReport } from '../services/api';\n\nfunction InsightsCard({ insights, jobId }) {\n  const { title, summary, kpis, bullets, recommendations } = insights;\n\n  const getIconComponent = (iconName) => {\n    const icons = {\n      'chart-line': TrendingUp,\n      'trending-up': TrendingUp,\n      'trending-down': TrendingDown,\n      'calendar': Calendar,\n      'calendar-check': Calendar,\n      'check-circle': CheckCircle,\n      'check': CheckCircle,\n      'alert-triangle': AlertTriangle,\n      'zap': Zap,\n      'minus': Minus,\n      'info': Info,\n    };\n    return icons[iconName] || Info;\n  };\n\n  const getSeverityStyles = (severity) => {\n    const styles = {\n      success: 'bg-green-50 border-green-200 text-green-800',\n      warning: 'bg-amber-50 border-amber-200 text-amber-800',\n      info: 'bg-blue-50 border-blue-200 text-blue-800',\n      error: 'bg-red-50 border-red-200 text-red-800',\n    };\n    return styles[severity] || styles.info;\n  };\n\n  const getTrendIcon = (trend) => {\n    if (trend === 'up') return <TrendingUp size={16} className=\"text-green-500\" />;\n    if (trend === 'down') return <TrendingDown size={16} className=\"text-red-500\" />;\n    return <Minus size={16} className=\"text-gray-400\" />;\n  };\n\n  const getPriorityStyles = (priority) => {\n    const styles = {\n      high: 'border-red-200 bg-red-50',\n      medium: 'border-amber-200 bg-amber-50',\n      low: 'border-blue-200 bg-blue-50',\n    };\n    return styles[priority] || styles.medium;\n  };\n\n  const getCategoryIcon = (category) => {\n    const icons = {\n      'Inventory': Package,\n      'Promotion': Zap,\n      'Pricing': DollarSign,\n      'Data Quality': Info,\n    };\n    const Icon = icons[category] || Lightbulb;\n    return <Icon size={20} />;\n  };\n\n  const handleDownload = async () => {\n    try {\n      await downloadReport(jobId, 'pdf');\n    } catch (err) {\n      console.error('Download failed:', err);\n    }\n  };\n\n  return (\n    <div className=\"bg-white rounded-xl shadow-sm border border-gray-100 overflow-hidden\">\n      <div className=\"gradient-bg p-6 text-white\">\n        <div className=\"flex items-start justify-between\">\n          <div className=\"flex items-center gap-3\">\n            <div className=\"p-2 bg-white/20 rounded-lg\">\n              <Lightbulb size={24} />\n            </div>\n            <div>\n              <h2 className=\"text-xl font-bold\">{title}</h2>\n              <p className=\"text-blue-100 text-sm\">AI-Generated Business Insights</p>\n            </div>\n          </div>\n          <button\n            onClick={handleDownload}\n            className=\"flex items-center gap-2 px-4 py-2 bg-white/20 rounded-lg hover:bg-white/30 transition-colors\"\n          >\n            <Download size={18} />\n            Download Report\n          </button>\n        </div>\n      </div>\n\n      <div className=\"p-6 space-y-6\">\n        <div className=\"bg-gray-50 rounded-lg p-4\">\n          <p className=\"text-gray-700 leading-relaxed\">{summary}</p>\n        </div>\n\n        <div>\n          <h3 className=\"font-semibold text-gray-800 mb-4\">Key Performance Indicators</h3>\n          <div className=\"grid grid-cols-2 md:grid-cols-4 gap-4\">\n            {kpis.map((kpi, idx) => (\n              <div key={idx} className=\"bg-gray-50 rounded-lg p-4\">\n                <div className=\"flex items-center justify-between mb-1\">\n                  <span className=\"text-sm text-gray-500\">{kpi.name}</span>\n                  {getTrendIcon(kpi.trend)}\n                </div>\n                <p className=\"text-xl font-bold text-gray-800\">{kpi.value}</p>\n                {kpi.change && (\n                  <p className=\"text-xs text-gray-500 mt-1\">{kpi.change}</p>\n                )}\n              </div>\n            ))}\n          </div>\n        </div>\n\n        <div>\n          <h3 className=\"font-semibold text-gray-800 mb-4\">Key Insights</h3>\n          <div className=\"space-y-3\">\n            {bullets.map((bullet, idx) => {\n              const Icon = getIconComponent(bullet.icon);\n              return (\n                <div \n                  key={idx} \n                  className={`flex items-start gap-3 p-4 rounded-lg border ${getSeverityStyles(bullet.severity)}`}\n                >\n                  <Icon size={20} className=\"mt-0.5 flex-shrink-0\" />\n                  <p className=\"text-sm\">{bullet.text}</p>\n                </div>\n              );\n            })}\n          </div>\n        </div>\n\n        <div>\n          <h3 className=\"font-semibold text-gray-800 mb-4\">Recommendations</h3>\n          <div className=\"grid md:grid-cols-3 gap-4\">\n            {recommendations.map((rec, idx) => (\n              <div \n                key={idx} \n                className={`p-4 rounded-lg border-2 ${getPriorityStyles(rec.priority)}`}\n              >\n                <div className=\"flex items-center gap-2 mb-2\">\n                  <span className={`p-1.5 rounded-lg ${\n                    rec.priority === 'high' ? 'bg-red-100 text-red-600' :\n                    rec.priority === 'medium' ? 'bg-amber-100 text-amber-600' :\n                    'bg-blue-100 text-blue-600'\n                  }`}>\n                    {getCategoryIcon(rec.category)}\n                  </span>\n                  <span className=\"text-xs font-medium uppercase tracking-wide text-gray-500\">\n                    {rec.category}\n                  </span>\n                </div>\n                <h4 className=\"font-semibold text-gray-800 mb-2\">{rec.title}</h4>\n                <p className=\"text-sm text-gray-600\">{rec.description}</p>\n                <div className=\"mt-3 pt-2 border-t border-gray-200\">\n                  <span className={`text-xs font-medium px-2 py-1 rounded-full ${\n                    rec.priority === 'high' ? 'bg-red-200 text-red-800' :\n                    rec.priority === 'medium' ? 'bg-amber-200 text-amber-800' :\n                    'bg-blue-200 text-blue-800'\n                  }`}>\n                    {rec.priority.toUpperCase()} PRIORITY\n                  </span>\n                </div>\n              </div>\n            ))}\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n\nexport default InsightsCard;\n","path":null,"size_bytes":6274,"size_tokens":null},"AISalesForecaster/backend/app/models/database.py":{"content":"import sqlite3\nimport json\nimport os\nfrom datetime import datetime\nfrom typing import Optional, Dict, Any, List\nfrom contextlib import contextmanager\n\nDATABASE_PATH = os.environ.get(\"DATABASE_PATH\", \"backend/data/forecaster.db\")\n\n\ndef init_database():\n    os.makedirs(os.path.dirname(DATABASE_PATH), exist_ok=True)\n    \n    with get_connection() as conn:\n        cursor = conn.cursor()\n        \n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS jobs (\n                job_id TEXT PRIMARY KEY,\n                created_at TEXT NOT NULL,\n                updated_at TEXT NOT NULL,\n                status TEXT DEFAULT 'pending',\n                file_path TEXT,\n                original_filename TEXT,\n                row_count INTEGER,\n                column_count INTEGER,\n                columns TEXT,\n                date_range TEXT,\n                validation_result TEXT\n            )\n        \"\"\")\n        \n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS forecasts (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                job_id TEXT NOT NULL,\n                created_at TEXT NOT NULL,\n                model_type TEXT,\n                aggregation TEXT,\n                horizon INTEGER,\n                target_column TEXT,\n                group_by TEXT,\n                metrics TEXT,\n                forecast_data TEXT,\n                historical_data TEXT,\n                decomposition_data TEXT,\n                feature_importance TEXT,\n                top_products TEXT,\n                top_regions TEXT,\n                FOREIGN KEY (job_id) REFERENCES jobs(job_id)\n            )\n        \"\"\")\n        \n        cursor.execute(\"\"\"\n            CREATE TABLE IF NOT EXISTS insights (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                job_id TEXT NOT NULL,\n                created_at TEXT NOT NULL,\n                title TEXT,\n                summary TEXT,\n                kpis TEXT,\n                bullets TEXT,\n                recommendations TEXT,\n                FOREIGN KEY (job_id) REFERENCES jobs(job_id)\n            )\n        \"\"\")\n        \n        conn.commit()\n\n\n@contextmanager\ndef get_connection():\n    conn = sqlite3.connect(DATABASE_PATH)\n    conn.row_factory = sqlite3.Row\n    try:\n        yield conn\n    finally:\n        conn.close()\n\n\ndef create_job(job_id: str, file_path: str, original_filename: str, \n               row_count: int, column_count: int, columns: List[str],\n               date_range: Dict, validation_result: Dict) -> None:\n    now = datetime.utcnow().isoformat()\n    \n    with get_connection() as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            INSERT INTO jobs (job_id, created_at, updated_at, status, file_path,\n                            original_filename, row_count, column_count, columns,\n                            date_range, validation_result)\n            VALUES (?, ?, ?, 'uploaded', ?, ?, ?, ?, ?, ?, ?)\n        \"\"\", (\n            job_id, now, now, file_path, original_filename,\n            row_count, column_count, json.dumps(columns),\n            json.dumps(date_range), json.dumps(validation_result)\n        ))\n        conn.commit()\n\n\ndef get_job(job_id: str) -> Optional[Dict[str, Any]]:\n    with get_connection() as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT * FROM jobs WHERE job_id = ?\", (job_id,))\n        row = cursor.fetchone()\n        \n        if row:\n            job = dict(row)\n            job['columns'] = json.loads(job['columns']) if job['columns'] else []\n            job['date_range'] = json.loads(job['date_range']) if job['date_range'] else {}\n            job['validation_result'] = json.loads(job['validation_result']) if job['validation_result'] else {}\n            return job\n        return None\n\n\ndef update_job_status(job_id: str, status: str) -> None:\n    now = datetime.utcnow().isoformat()\n    \n    with get_connection() as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            UPDATE jobs SET status = ?, updated_at = ? WHERE job_id = ?\n        \"\"\", (status, now, job_id))\n        conn.commit()\n\n\ndef save_forecast(job_id: str, model_type: str, aggregation: str, \n                  horizon: int, target_column: str, group_by: Optional[str],\n                  metrics: Dict, forecast_data: List, historical_data: List,\n                  decomposition_data: Optional[Dict], feature_importance: Optional[List],\n                  top_products: Optional[List], top_regions: Optional[List]) -> int:\n    now = datetime.utcnow().isoformat()\n    \n    with get_connection() as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            INSERT INTO forecasts (job_id, created_at, model_type, aggregation,\n                                  horizon, target_column, group_by, metrics,\n                                  forecast_data, historical_data, decomposition_data,\n                                  feature_importance, top_products, top_regions)\n            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n        \"\"\", (\n            job_id, now, model_type, aggregation, horizon, target_column, group_by,\n            json.dumps(metrics), json.dumps(forecast_data), json.dumps(historical_data),\n            json.dumps(decomposition_data) if decomposition_data else None,\n            json.dumps(feature_importance) if feature_importance else None,\n            json.dumps(top_products) if top_products else None,\n            json.dumps(top_regions) if top_regions else None\n        ))\n        conn.commit()\n        return cursor.lastrowid\n\n\ndef get_latest_forecast(job_id: str) -> Optional[Dict[str, Any]]:\n    with get_connection() as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT * FROM forecasts WHERE job_id = ? ORDER BY created_at DESC LIMIT 1\n        \"\"\", (job_id,))\n        row = cursor.fetchone()\n        \n        if row:\n            forecast = dict(row)\n            forecast['metrics'] = json.loads(forecast['metrics']) if forecast['metrics'] else {}\n            forecast['forecast_data'] = json.loads(forecast['forecast_data']) if forecast['forecast_data'] else []\n            forecast['historical_data'] = json.loads(forecast['historical_data']) if forecast['historical_data'] else []\n            forecast['decomposition_data'] = json.loads(forecast['decomposition_data']) if forecast['decomposition_data'] else None\n            forecast['feature_importance'] = json.loads(forecast['feature_importance']) if forecast['feature_importance'] else None\n            forecast['top_products'] = json.loads(forecast['top_products']) if forecast['top_products'] else None\n            forecast['top_regions'] = json.loads(forecast['top_regions']) if forecast['top_regions'] else None\n            return forecast\n        return None\n\n\ndef save_insights(job_id: str, title: str, summary: str,\n                  kpis: List, bullets: List, recommendations: List) -> int:\n    now = datetime.utcnow().isoformat()\n    \n    with get_connection() as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            INSERT INTO insights (job_id, created_at, title, summary, kpis, bullets, recommendations)\n            VALUES (?, ?, ?, ?, ?, ?, ?)\n        \"\"\", (\n            job_id, now, title, summary,\n            json.dumps(kpis), json.dumps(bullets), json.dumps(recommendations)\n        ))\n        conn.commit()\n        return cursor.lastrowid\n\n\ndef get_latest_insights(job_id: str) -> Optional[Dict[str, Any]]:\n    with get_connection() as conn:\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT * FROM insights WHERE job_id = ? ORDER BY created_at DESC LIMIT 1\n        \"\"\", (job_id,))\n        row = cursor.fetchone()\n        \n        if row:\n            insights = dict(row)\n            insights['kpis'] = json.loads(insights['kpis']) if insights['kpis'] else []\n            insights['bullets'] = json.loads(insights['bullets']) if insights['bullets'] else []\n            insights['recommendations'] = json.loads(insights['recommendations']) if insights['recommendations'] else []\n            return insights\n        return None\n","path":null,"size_bytes":8125,"size_tokens":null},"AISalesForecaster/backend/app/routes/download.py":{"content":"import os\nimport io\nimport pandas as pd\nfrom fastapi import APIRouter, HTTPException, Query\nfrom fastapi.responses import StreamingResponse\nfrom datetime import datetime\nimport logging\n\nfrom reportlab.lib import colors\nfrom reportlab.lib.pagesizes import letter, A4\nfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\nfrom reportlab.lib.units import inch\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle\nfrom reportlab.lib.enums import TA_CENTER, TA_LEFT\n\nfrom ..models.schemas import DownloadFormat\nfrom ..models.database import get_job, get_latest_forecast, get_latest_insights\n\nrouter = APIRouter()\nlogger = logging.getLogger(__name__)\n\n\n@router.get(\"/download\")\nasync def download_report(\n    job_id: str = Query(..., description=\"Job ID\"),\n    format: DownloadFormat = Query(DownloadFormat.CSV, description=\"Download format\")\n):\n    job = get_job(job_id)\n    if not job:\n        raise HTTPException(status_code=404, detail=\"Job not found\")\n    \n    forecast = get_latest_forecast(job_id)\n    if not forecast:\n        raise HTTPException(status_code=404, detail=\"No forecast found\")\n    \n    try:\n        if format == DownloadFormat.CSV:\n            return await generate_csv(job_id, forecast)\n        else:\n            return await generate_pdf(job_id, job, forecast)\n            \n    except Exception as e:\n        logger.error(f\"Download error: {str(e)}\")\n        raise HTTPException(status_code=500, detail=f\"Error generating download: {str(e)}\")\n\n\nasync def generate_csv(job_id: str, forecast: dict) -> StreamingResponse:\n    historical_data = forecast.get('historical_data', [])\n    forecast_data = forecast.get('forecast_data', [])\n    \n    all_data = []\n    \n    for point in historical_data:\n        all_data.append({\n            'date': point['date'],\n            'actual': point.get('actual'),\n            'predicted': point.get('predicted'),\n            'lower_bound': point.get('lower_bound'),\n            'upper_bound': point.get('upper_bound'),\n            'type': 'historical'\n        })\n    \n    for point in forecast_data:\n        all_data.append({\n            'date': point['date'],\n            'actual': None,\n            'predicted': point.get('predicted'),\n            'lower_bound': point.get('lower_bound'),\n            'upper_bound': point.get('upper_bound'),\n            'type': 'forecast'\n        })\n    \n    df = pd.DataFrame(all_data)\n    \n    buffer = io.StringIO()\n    df.to_csv(buffer, index=False)\n    buffer.seek(0)\n    \n    filename = f\"forecast_{job_id}_{datetime.now().strftime('%Y%m%d')}.csv\"\n    \n    return StreamingResponse(\n        iter([buffer.getvalue()]),\n        media_type=\"text/csv\",\n        headers={\"Content-Disposition\": f\"attachment; filename={filename}\"}\n    )\n\n\nasync def generate_pdf(job_id: str, job: dict, forecast: dict) -> StreamingResponse:\n    buffer = io.BytesIO()\n    doc = SimpleDocTemplate(buffer, pagesize=letter, topMargin=0.5*inch, bottomMargin=0.5*inch)\n    \n    styles = getSampleStyleSheet()\n    title_style = ParagraphStyle(\n        'CustomTitle',\n        parent=styles['Heading1'],\n        fontSize=18,\n        textColor=colors.HexColor('#1e40af'),\n        spaceAfter=20,\n        alignment=TA_CENTER\n    )\n    heading_style = ParagraphStyle(\n        'CustomHeading',\n        parent=styles['Heading2'],\n        fontSize=14,\n        textColor=colors.HexColor('#1f2937'),\n        spaceBefore=15,\n        spaceAfter=10\n    )\n    body_style = ParagraphStyle(\n        'CustomBody',\n        parent=styles['Normal'],\n        fontSize=10,\n        textColor=colors.HexColor('#374151'),\n        spaceAfter=8\n    )\n    \n    elements = []\n    \n    elements.append(Paragraph(\"AI Sales Forecaster Report\", title_style))\n    elements.append(Paragraph(f\"Generated: {datetime.now().strftime('%B %d, %Y')}\", body_style))\n    elements.append(Spacer(1, 20))\n    \n    elements.append(Paragraph(\"Forecast Summary\", heading_style))\n    \n    metrics = forecast.get('metrics', {})\n    summary_data = [\n        ['Model Type', forecast.get('model_type', 'N/A').upper()],\n        ['Aggregation', forecast.get('aggregation', 'N/A').title()],\n        ['Horizon', f\"{forecast.get('horizon', 'N/A')} months\"],\n        ['Target Column', forecast.get('target_column', 'N/A').title()],\n        ['MAE', f\"{metrics.get('mae', 'N/A')}\"],\n        ['RMSE', f\"{metrics.get('rmse', 'N/A')}\"],\n        ['MAPE', f\"{metrics.get('mape', 'N/A')}%\"],\n    ]\n    \n    summary_table = Table(summary_data, colWidths=[2*inch, 3*inch])\n    summary_table.setStyle(TableStyle([\n        ('BACKGROUND', (0, 0), (0, -1), colors.HexColor('#f3f4f6')),\n        ('TEXTCOLOR', (0, 0), (-1, -1), colors.HexColor('#1f2937')),\n        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n        ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),\n        ('FONTSIZE', (0, 0), (-1, -1), 10),\n        ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n        ('TOPPADDING', (0, 0), (-1, -1), 8),\n        ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e5e7eb')),\n    ]))\n    elements.append(summary_table)\n    elements.append(Spacer(1, 20))\n    \n    insights = get_latest_insights(job_id)\n    if insights:\n        elements.append(Paragraph(\"Business Insights\", heading_style))\n        elements.append(Paragraph(insights.get('summary', ''), body_style))\n        elements.append(Spacer(1, 10))\n        \n        bullets = insights.get('bullets', [])\n        for bullet in bullets:\n            text = bullet.get('text', '') if isinstance(bullet, dict) else str(bullet)\n            elements.append(Paragraph(f\" {text}\", body_style))\n        \n        elements.append(Spacer(1, 15))\n        \n        elements.append(Paragraph(\"Recommendations\", heading_style))\n        recommendations = insights.get('recommendations', [])\n        for i, rec in enumerate(recommendations, 1):\n            if isinstance(rec, dict):\n                title = rec.get('title', '')\n                desc = rec.get('description', '')\n                elements.append(Paragraph(f\"{i}. <b>{title}</b>: {desc}\", body_style))\n            else:\n                elements.append(Paragraph(f\"{i}. {rec}\", body_style))\n    \n    elements.append(Spacer(1, 20))\n    \n    elements.append(Paragraph(\"Forecast Data (Preview)\", heading_style))\n    \n    forecast_data = forecast.get('forecast_data', [])[:10]\n    if forecast_data:\n        table_data = [['Date', 'Predicted', 'Lower Bound', 'Upper Bound']]\n        for point in forecast_data:\n            table_data.append([\n                point.get('date', ''),\n                f\"{point.get('predicted', 0):,.2f}\",\n                f\"{point.get('lower_bound', 0):,.2f}\",\n                f\"{point.get('upper_bound', 0):,.2f}\"\n            ])\n        \n        forecast_table = Table(table_data, colWidths=[1.5*inch, 1.5*inch, 1.5*inch, 1.5*inch])\n        forecast_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e40af')),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),\n            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, -1), 9),\n            ('BOTTOMPADDING', (0, 0), (-1, -1), 6),\n            ('TOPPADDING', (0, 0), (-1, -1), 6),\n            ('GRID', (0, 0), (-1, -1), 0.5, colors.HexColor('#e5e7eb')),\n            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f9fafb')]),\n        ]))\n        elements.append(forecast_table)\n    \n    doc.build(elements)\n    buffer.seek(0)\n    \n    filename = f\"forecast_report_{job_id}_{datetime.now().strftime('%Y%m%d')}.pdf\"\n    \n    return StreamingResponse(\n        buffer,\n        media_type=\"application/pdf\",\n        headers={\"Content-Disposition\": f\"attachment; filename={filename}\"}\n    )\n","path":null,"size_bytes":7745,"size_tokens":null}},"version":2}